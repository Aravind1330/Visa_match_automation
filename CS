def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            return matching_invoices, match_rule

    return [], None


def match_bundle(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):
                matching_invoices.append((Invoice, rule_index))
                total_invoice_source_amt += float(Invoice['inv_match_source_amt'])
                break

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            return matching_invoices, match_rule

    return [], None


output_rows_one_to_one = []
unmatched_output_rows_one_to_one = []
output_rows_bundle = []
unmatched_output_rows_bundle = []
matched_invoices = []

for T5 in T5_table:
    matching_invoices, match_rule = match_one_to_one(T5, Invoice_table)
    match_type = "one-to-one"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(match_rule)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_rows_one_to_one.append(output_row)
            matched_invoices.append(invoice)

        # Remove the matched invoice from Invoice_table
        Invoice_table = [inv for inv in Invoice_table if inv not in matched_invoices]

        # Remove the matched transaction from T5_table
        T5_table = [T5_row for T5_row in T5_table if T5_row['fin_record_key'] != T5['fin_record_key']]
        unmatched_fin_record_keys.remove(T5['fin_record_key'])

        unmatched_indices = unmatched_output_df[
            (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
            (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt']) &
            (unmatched_output_df['fin_debit_credit_ind'] == T5['fin_debit_credit_ind'])
        ].index

        unmatched_output_df.drop(unmatched_indices, inplace=True)

    else:
        unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
        unmatched_output_rows_one_to_one.append(unmatched_output_row)
        unmatched_fin_record_keys.add(T5['fin_record_key'])

for T5 in T5_table:
    matching_invoices, match_rule = match_bundle(T5, Invoice_table)
    match_type = "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(match_rule)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_rows_bundle.append(output_row)
            matched_invoices.append(invoice)

        # Remove the matched invoices from Invoice_table
        Invoice_table = [inv for inv in Invoice_table if inv not in matched_invoices]

        # Remove the matched transaction from T5_table
        T5_table = [T5_row for T5_row in T5_table if T5_row['fin_record_key'] != T5['fin_record_key']]
        unmatched_fin_record_keys.discard(T5['fin_record_key'])

        unmatched_indices = unmatched_output_df[
            (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
            (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
        ].index

        unmatched_output_df.drop(unmatched_indices, inplace=True)

    else:
        unmatched_output_rows_bundle.append(T5)












import re

def is_valid_rule(T5, Invoice):
    authno_T5 = T5['authno']
    authno_Invoice = Invoice['authno']

    if authno_T5.isalpha() and authno_Invoice.isalpha():
        return False  # Both values are alphabetic, so not a valid match
    else:
        return authno_T5 == authno_Invoice

def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None
    invoices_to_remove = []

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if (
                rule(T5, Invoice=Invoice)
                and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt'])
                and is_valid_rule(T5, Invoice)  # Check if the rule is valid
            ):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                invoices_to_remove.append(Invoice)
                break

    for invoice in invoices_to_remove:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None


def match_bundle(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None
    invoices_to_remove = []

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if (
                rule(T5, Invoice=Invoice)
                and is_valid_rule(T5, Invoice)  # Check if the rule is valid
            ):
                matching_invoices.append((Invoice, rule_index))
                total_invoice_source_amt += float(Invoice['inv_match_source_amt'])
                invoices_to_remove.append(Invoice)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            break

    for invoice in invoices_to_remove:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None






def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for i, Invoice in enumerate(Invoice_table):
        if Invoice in matching_invoices:
            continue  # Skip already matched invoices

        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            break

    for invoice, _ in matching_invoices:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None





def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None

    for rule_index, rule in enumerate(rules, start=1):
        matched_invoices = []

        for Invoice in unmatched_invoices:
            if rule(T5, Invoice=Invoice):
                invoice_amt = float(Invoice['inv_match_source_amt'])
                remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt

                if invoice_amt <= remaining_amt:
                    matched_invoices.append((Invoice, rule_index))

        if matched_invoices:
            best_match = max(matched_invoices, key=lambda x: float(x[0]['inv_match_source_amt']))
            matching_invoices.append(best_match)
            total_invoice_source_amt += float(best_match[0]['inv_match_source_amt'])
            unmatched_invoices.remove(best_match[0])
            match_rule = rule_index

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            break

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices







def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None

    for rule_index, rule in enumerate(rules, start=1):
        for i in range(len(unmatched_invoices)):
            Invoice = unmatched_invoices[i]
            if Invoice in matching_invoices:
                continue  # Skip already matched invoices

            if rule(T5, Invoice=Invoice):
                invoice_amt = float(Invoice['inv_match_source_amt'])
                remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt

                if invoice_amt <= remaining_amt:
                    matching_invoices.append((Invoice, rule_index))
                    total_invoice_source_amt += invoice_amt

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices






import pandas as pd

def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule_index == 25 and (
                (T5['fin_orig_supplier_nm'] is None or pd.isnull(T5['fin_orig_supplier_nm'])) and
                (Invoice['inv_ticket_num'] is None or pd.isnull(Invoice['inv_ticket_num']))
            ):
                continue

            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            break

    return matching_invoices, match_rule









import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Assuming you have two DataFrames representing the tables
finrecord_df = pd.DataFrame(data={'finrecord_key': [1, 2, 3], 'column1': [...], 'column2': [...]})
invoice_df = pd.DataFrame(data={'invoice_id': [101, 102, 103], 'column1': [...], 'column2': [...]})

# Assuming you have two arrays representing the desired columns for each table
table1_columns = finrecord_df[['column1', 'column2', ...]].values
table2_columns = invoice_df[['column1', 'column2', ...]].values

similarity_matrix = cosine_similarity(table1_columns, table2_columns)

column_thresholds = {
    'column1': 0.8,
    'column2': 0.9,
    ...
}

matching_pairs = []
for i, row in enumerate(similarity_matrix):
    for j, score in enumerate(row):
        if all(score >= threshold for threshold in column_thresholds.values()):
            matching_pairs.append((i, j))

unmatched_invoice_ids = set(range(len(table2_columns)))

for pair in matching_pairs:
    finrecord_key = finrecord_df['finrecord_key'].iloc[pair[0]]  # finrecord_key from Table 1
    invoice_id = invoice_df['invoice_id'].iloc[pair[1]]  # invoice_id from Table 2
    unmatched_invoice_ids.remove(pair[1])
    print(f"Matching pair: finrecord_key={finrecord_key}, invoice_id={invoice_id}")

for unmatched_id in unmatched_invoice_ids:
    invoice_id = invoice_df['invoice_id'].iloc[unmatched_id]  # invoice_id from Table 2
    print(f"Unmatched invoice_id: {invoice_id}")







import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction.text import CountVectorizer

# Assuming you have two DataFrames representing the tables
finrecord_df = pd.DataFrame(data={'finrecord_key': [1, 2, 3], 'column1': ['text1', 'text2', 'text3'], 'column2': ['A', 'B', 'C']})
invoice_df = pd.DataFrame(data={'invoice_id': [101, 102, 103], 'column1': ['text2', 'text4', 'text1'], 'column2': ['B', 'D', 'A']})

# Text preprocessing
text_cols = ['column1']
for col in text_cols:
    finrecord_df[col] = finrecord_df[col].str.lower().replace('[^a-zA-Z0-9]', '', regex=True)
    invoice_df[col] = invoice_df[col].str.lower().replace('[^a-zA-Z0-9]', '', regex=True)

# One-hot encoding for alphanumeric columns
alphanumeric_cols = ['column2']
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

# Fit and transform the encoder on the combined dataset of both tables
combined_df = pd.concat([finrecord_df[alphanumeric_cols], invoice_df[alphanumeric_cols]])
encoded_features = encoder.fit_transform(combined_df)

# Split the encoded features back into separate arrays for each table
num_finrecord_rows = len(finrecord_df)
encoded_finrecord = encoded_features[:num_finrecord_rows]
encoded_invoice = encoded_features[num_finrecord_rows:]

# Assuming you have two arrays representing the desired columns for each table
table1_columns = np.concatenate((finrecord_df[text_cols].values, encoded_finrecord), axis=1)
table2_columns = np.concatenate((invoice_df[text_cols].values, encoded_invoice), axis=1)

# Calculate cosine similarity
similarity_matrix = cosine_similarity(table1_columns, table2_columns)

column_thresholds = {
    'column1': 0.8,
    'column2': 0.9,
    ...
}

matching_pairs = []
for i, row in enumerate(similarity_matrix):
    for j, score in enumerate(row):
        if all(score >= threshold for threshold in column_thresholds.values()):
            matching_pairs.append((i, j))

unmatched_invoice_ids = set(range(len(table2_columns)))

for pair in matching_pairs:
    finrecord_key = finrecord_df['finrecord_key'].iloc[pair[0]]  # finrecord_key from Table 1
    invoice_id = invoice_df['invoice_id'].iloc[pair[1]]  # invoice_id from Table 2
    unmatched_invoice_ids.remove(pair[1])
    print(f"Matching pair: finrecord_key={finrecord_key}, invoice_id={invoice_id}")

for unmatched_id in unmatched_invoice_ids:
    invoice_id = invoice_df['invoice_id'].iloc[unmatched_id]  # invoice_id from Table 2
    print(f"Unmatched invoice_id: {invoice_id}")














import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'other_column']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data['ticket_number'].astype(str).str[:5]

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_features)

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

# Add threshold values for each column
thresholds = {
    'supplier_name': 0.8,
    'source_amount': 0.9,
    'other_column': 0.7
}

# Find the best matches
threshold = 0.8  # Adjust the threshold based on your needs
matches = []
for transaction_idx, transaction_name in enumerate(transaction_features['supplier_name']):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx, _ in enumerate(invoice_features):
        if invoice_idx not in matched_indices:  # Check if the invoice has already been matched
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            if similarity_score > best_match_score:
                best_match_score = similarity_score
                best_match_idx = invoice_idx
    if best_match_score >= threshold:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matches.append((transaction_id, invoice_id, best_match_idx, best_match_score))
        matched_indices.add(best_match_idx)

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Best Match Index, Score\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {match[2]}, {match[3]}\n")
        print(f"Match found: Transaction ID {match[0]} -> Invoice ID {match[1]}, "
              f"Best Match Index: {match[2]}, Score: {match[3]}")

print(f"Matches saved to {output_file}")











matches = []
for transaction_idx, transaction_name in enumerate(transaction_features['supplier_name']):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx, _ in enumerate(invoice_features):
        if invoice_idx not in matched_indices:  # Check if the invoice has already been matched
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            if similarity_score > best_match_score:
                # Check if the best match score meets the threshold for each column
                if (similarity_score >= thresholds['supplier_name'] and
                        float(transaction_features.iloc[transaction_idx]['source_amount']) >= thresholds['source_amount'] and
                        float(transaction_features.iloc[transaction_idx]['other_column']) >= thresholds['other_column']):
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    if best_match_idx != -1:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matches.append((transaction_id, invoice_id, best_match_idx, best_match_score))
        matched_indices.add(best_match_idx)








import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'other_column']
invoice_columns = ['invoice_number', 'customer_name', 'invoice_amount']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data[invoice_columns].astype(str)

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_features['customer_name'])

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

thresholds = {'supplier_name': 0.1, 'source_amount': 0.2, 'other_column': 0.3}

# Find the best matches
matches = []
for transaction_idx in range(len(transaction_data)):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx in range(len(invoice_data)):
        if invoice_idx not in matched_indices:  # Skip already matched invoices
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            match_scores = []
            for column in transaction_columns:
                if column in invoice_columns:
                    column_index = invoice_columns.index(column)
                    threshold = thresholds[column]
                    column_similarity_score = cosine_similarity(
                        vectorizer.transform([transaction_features.loc[transaction_idx, column]]),
                        vectorizer.transform([invoice_features.loc[invoice_idx, column_index]])
                    )[0][0]
                    match_scores.append(column_similarity_score)
            if all(score >= threshold for score, threshold in zip(match_scores, thresholds.values())):
                if similarity_score > best_match_score:
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    if best_match_idx != -1:
        matched_indices.add(best_match_idx)  # Add the matched invoice index to the set
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matched_column = [column for column, score in zip(transaction_columns, match_scores) if score >= thresholds[column]]
        transaction_values = transaction_data.iloc[transaction_idx][transaction_columns]
        invoice_values = invoice_data.iloc[best_match_idx][invoice_columns]
        matches.append((transaction_id, invoice_id, transaction_values, invoice_values, matched_column))

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Matched Column, Transaction Values, Invoice Values\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {match[4]}, {match[2]}, {match[3]}\n")
        print(f"Match found: Transaction ID {match[0]} -> Invoice ID {match[1]}")
        print(f"Matched Column: {match[4]}")
        print(f"Transaction Values: {match[2]}")
        print(f"Invoice Values: {match[3]}\n")

print(f"Matches saved to {output_file}")










import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'other_column']
invoice_columns = ['invoice_number', 'customer_name', 'invoice_amount']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data[invoice_columns].astype(str)

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_features['customer_name'])

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

thresholds = {'supplier_name': 0.1, 'source_amount': None, 'other_column': 0.3}

# Find the best matches
matches = []
for transaction_idx in range(len(transaction_data)):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx in range(len(invoice_data)):
        if invoice_idx not in matched_indices:  # Skip already matched invoices
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            match_scores = []
            for column in transaction_columns:
                if column in invoice_columns:
                    column_index = invoice_columns.index(column)
                    threshold = thresholds[column]
                    if column == 'source_amount':
                        if transaction_features.loc[transaction_idx, column] == invoice_features.loc[invoice_idx, column_index]:
                            match_scores.append(1.0)
                        else:
                            match_scores.append(0.0)
                    else:
                        column_similarity_score = cosine_similarity(
                            vectorizer.transform([transaction_features.loc[transaction_idx, column]]),
                            vectorizer.transform([invoice_features.loc[invoice_idx, column_index]])
                        )[0][0]
                        match_scores.append(column_similarity_score)
            if all(score >= threshold for score, threshold in zip(match_scores, thresholds.values())):
                if similarity_score > best_match_score:
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    if best_match_idx != -1:
        matched_indices.add(best_match_idx)  # Add the matched invoice index to the set
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matched_columns = [column for column, score in zip(transaction_columns, match_scores) if score >= thresholds[column]]
        transaction_amt = transaction_data.iloc[transaction_idx]['source_amount']
        invoice_amt = invoice_data.iloc[best_match_idx]['invoice_amount']
        matches.append((transaction_id, invoice_id, matched_columns, transaction_amt, invoice_amt))

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Fin Record Key, Invoice ID, Matched Columns, Transaction Amount, Invoice Amount\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {', '.join(match[2])}, {match[3]}, {match[4]}\n")
        print(f"Match found: Fin Record Key {match[0]} -> Invoice ID {match[1]}")
        print(f"Matched Columns: {', '.join(match[2])}")
        print(f"Transaction Amount: {match[3]}")
        print(f"Invoice Amount: {match[4]}\n")

print(f"Matches saved to {output_file}")
















from sklearn.metrics.pairwise import cosine_similarity

threshold = 70
matches = []
count = 0

for transaction_idx, transaction_row in transaction_features.iterrows():
    amt = transaction_row['fin_source_amt']
    debit_credit_indicator = transaction_row['fin debit credit_ind']
    transaction_account_no = transaction_row['fin_acct_num (masked)']

    best_match_score = -1
    best_match_idx = -1

    for invoice_idx, invoice_row in invoice_features.items():
        if invoice_idx not in matched_indices: # Check if the invoice has already been matched
            invoice_amount = invoice_amt[invoice_idx]
            invoice_credit_debit = invoice_debit_credit_indicator[invoice_idx]
            inv_account = invoice_account_number[invoice_idx]
            inv_account_final = inv_account[-4:]

            source_amt_score = cosine_similarity(amt, invoice_amount)
            c_or_d_indicator_score = cosine_similarity(debit_credit_indicator, invoice_credit_debit)
            account_no_score = cosine_similarity(transaction_account_no, inv_account_final)

            average_score = (source_amt_score + c_or_d_indicator_score + account_no_score) / 3

            if source_amt_score >= threshold and c_or_d_indicator_score >= threshold:
                matches.append((transaction_idx, invoice_idx, average_score))
                count += 1

print(count)





import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

threshold = 70
matches = []
count = 0

for transaction_idx, transaction_row in transaction_features.iterrows():
    amt = np.array(transaction_row['fin_source_amt']).reshape(1, -1)
    debit_credit_indicator = np.array(transaction_row['fin debit credit_ind']).reshape(1, -1)
    transaction_account_no = np.array(transaction_row['fin_acct_num (masked)']).reshape(1, -1)

    best_match_score = -1
    best_match_idx = -1

    for invoice_idx, invoice_row in invoice_features.items():
        if invoice_idx not in matched_indices: # Check if the invoice has already been matched
            invoice_amount = np.array(invoice_amt[invoice_idx]).reshape(1, -1)
            invoice_credit_debit = np.array(invoice_debit_credit_indicator[invoice_idx]).reshape(1, -1)
            inv_account = invoice_account_number[invoice_idx]
            inv_account_final = np.array(inv_account[-4:]).reshape(1, -1)

            source_amt_score = cosine_similarity(amt, invoice_amount)[0][0]
            c_or_d_indicator_score = cosine_similarity(debit_credit_indicator, invoice_credit_debit)[0][0]
            account_no_score = cosine_similarity(transaction_account_no, inv_account_final)[0][0]

            average_score = (source_amt_score + c_or_d_indicator_score + account_no_score) / 3

            if source_amt_score >= threshold and c_or_d_indicator_score >= threshold:
                matches.append((transaction_idx, invoice_idx, average_score))
                count += 1

print(count)


import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder

threshold = 70
matches = []
count = 0

# Label encoding for debit_credit_indicator column
label_encoder = LabelEncoder()
label_encoder.fit(transaction_features['fin debit credit_ind'])

for transaction_idx, transaction_row in transaction_features.iterrows():
    amt = np.array(transaction_row['fin_source_amt']).reshape(1, -1)
    debit_credit_indicator = np.array(label_encoder.transform([transaction_row['fin debit credit_ind']])).reshape(1, -1)
    transaction_account_no = np.array(transaction_row['fin_acct_num (masked)']).reshape(1, -1)

    best_match_score = -1
    best_match_idx = -1

    for invoice_idx, invoice_row in invoice_features.items():
        if invoice_idx not in matched_indices: # Check if the invoice has already been matched
            invoice_amount = np.array(invoice_amt[invoice_idx]).reshape(1, -1)
            invoice_credit_debit = np.array(label_encoder.transform([invoice_debit_credit_indicator[invoice_idx]])).reshape(1, -1)
            inv_account = invoice_account_number[invoice_idx]
            inv_account_final = np.array(inv_account[-4:]).reshape(1, -1)

            source_amt_score = cosine_similarity(amt, invoice_amount)[0][0]
            c_or_d_indicator_score = cosine_similarity(debit_credit_indicator, invoice_credit_debit)[0][0]
            account_no_score = cosine_similarity(transaction_account_no, inv_account_final)[0][0]

            average_score = (source_amt_score + c_or_d_indicator_score + account_no_score) / 3

            if source_amt_score >= threshold and c_or_d_indicator_score >= threshold:
                matches.append((transaction_idx, invoice_idx, average_score))
                count += 1

print(count)





import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'inv_number', 'source_amount', 'other_column']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data[['ticket_number', 'inv_number']].astype(str).apply(lambda x: ' '.join(x), axis=1)

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'] + ' ' + transaction_features['inv_number'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_features)

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

threshold = 0.1
# Find the best matches
matches = []
for transaction_idx in range(len(transaction_data)):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx in range(len(invoice_data)):
        similarity_score = similarity_matrix[transaction_idx, invoice_idx]
        if similarity_score > best_match_score and similarity_score >= threshold:
            best_match_score = similarity_score
            best_match_idx = invoice_idx
    if best_match_idx != -1:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        # Get the matching column values
        transaction_values = transaction_data.iloc[transaction_idx][transaction_columns]
        invoice_values = invoice_data.iloc[best_match_idx][['ticket_number', 'inv_number']]
        # Add matched values to the matches list
        matches.append((transaction_id, invoice_id, transaction_values, invoice_values))

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Supplier Name, Inv Number, Transaction Values, Invoice Values\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {match[2]}, {match[3]}\n")
        print(f"Match found: Transaction ID {match[0]} -> Invoice ID {match[1]}")
        print(f"Transaction Values: {match[2]}")
        print(f"Invoice Values: {match[3]}\n")

print(f"Matches saved to {output_file}")










import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'fin_purc_id', 'source_amt', 'other_column']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data[['supplier_name', 'ticket_number', 'inv_number', 'source_amt']].astype(str)

# Set the thresholds for each column
thresholds = {
    'supplier_name': 0.7,
    'fin_purc_id': 0.7,
    'source_amt': 0.9
}

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'])
invoice_vectors = vectorizer.transform(invoice_features['supplier_name'])

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

# Find the best matches
matches = []
for transaction_idx, transaction_row in transaction_features.iterrows():
    transaction_supplier = transaction_row['supplier_name']
    transaction_purc_id = transaction_row['fin_purc_id']
    transaction_source_amt = transaction_row['source_amt']
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx, invoice_row in invoice_features.iterrows():
        if invoice_idx not in matched_indices:  # Check if the invoice has already been matched
            invoice_supplier = invoice_row['supplier_name']
            invoice_ticket = invoice_row['ticket_number']
            invoice_inv = invoice_row['inv_number']
            invoice_source_amt = invoice_row['source_amt']

            supplier_score = cosine_similarity(transaction_vectors[transaction_idx], invoice_vectors[invoice_idx])[0][0]
            purc_id_score = cosine_similarity(vectorizer.transform([transaction_purc_id]), vectorizer.transform([invoice_ticket]))[0][0]
            inv_id_score = cosine_similarity(vectorizer.transform([transaction_purc_id]), vectorizer.transform([invoice_inv]))[0][0]
            source_amt_score = 1.0 if transaction_source_amt == invoice_source_amt else 0.0

            average_score = (supplier_score + purc_id_score + inv_id_score + source_amt_score) / 4

            if (
                supplier_score >= thresholds['supplier_name'] and
                purc_id_score >= thresholds['fin_purc_id'] and
                inv_id_score >= thresholds['fin_purc_id'] and
                source_amt_score >= thresholds['source_amt']
            ):
                best_match_score = average_score
                best_match_idx = invoice_idx

    if best_match_idx != -1:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        # Get the matching column values
        transaction_values = transaction_data.iloc[transaction_idx][transaction_columns]
        invoice_values = invoice_data.iloc[best_match_idx][transaction_columns]
        # Add matched values to the matches list
        matches.append((transaction_id, invoice_id, best_match_score, transaction_values, invoice_values))
        matched_indices.add(best_match_idx)

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Match Score, Transaction Values, Invoice Values\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {match[2]}, {match[3]}, {match[4]}\n")
        print(f"Match found: Transaction ID {match[0]} -> Invoice ID {match[1]}")
        print(f"Transaction Values: {match[3]}")
        print(f"Invoice Values: {match[4]}\n")

print(f"Matches saved to {output_file}")












import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'auth_no']
invoice_columns = ['ticket_number', 'inv_number', 'auth_no', 'amount', 'company_id']

# Set thresholds for each condition
thresholds = {
    'supplier_name_ticket': 0.1,
    'supplier_name_inv': 0.1,
    'auth_no': 0.1,
    'source_amount': 0.2,
}

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_data['supplier_name'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_data['ticket_number'].astype(str))

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

# Find the best matches
matches = []
for transaction_idx, transaction_row in transaction_data.iterrows():
    transaction_id = transaction_row['fin_record_key']
    transaction_supplier_name = transaction_row['supplier_name']
    transaction_source_amount = transaction_row['source_amount']
    transaction_auth_no = transaction_row['auth_no']
    
    best_match_score = -1
    best_match_idx = -1
    
    for invoice_idx, invoice_row in invoice_data.iterrows():
        invoice_ticket_number = str(invoice_row['ticket_number'])
        invoice_supplier_name = str(invoice_row['inv_number'])
        invoice_auth_no = invoice_row['auth_no']
        invoice_amount = invoice_row['amount']
        invoice_company_id = invoice_row['company_id']
        
        similarity_score = similarity_matrix[transaction_idx, invoice_idx]
        
        # Check if any condition is a match
        if (transaction_supplier_name == invoice_ticket_number and similarity_score >= thresholds['supplier_name_ticket']) or \
           (transaction_supplier_name == invoice_supplier_name and similarity_score >= thresholds['supplier_name_inv']) or \
           (transaction_auth_no == invoice_auth_no and similarity_score >= thresholds['auth_no']):
            
            if float(transaction_source_amount) == float(invoice_amount) and \
               transaction_data.loc[transaction_idx, 'company_id'] == invoice_company_id:
                if similarity_score > best_match_score:
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    
    if best_match_idx != -1:
        invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
        transaction_values = transaction_row[transaction_columns]
        invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
        matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score))

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Transaction Values, Invoice Values, Similarity Score\n")
    for match in matches:
        transaction_id, invoice_id, transaction_values, invoice_values, similarity_score = match
        file.write(f"{transaction_id}, {invoice_id}, {transaction_values}, {invoice_values}, {similarity_score}\n")













import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'auth_no']
invoice_columns = ['ticket_number', 'inv_number', 'auth_no', 'amount', 'company_id']

# Set thresholds for each condition
thresholds = {
    'supplier_name_ticket': 0.1,
    'supplier_name_inv': 0.1,
    'auth_no': 0.1,
    'source_amount': 0.2,
}

# Concatenate relevant columns into a single string representation for each row
transaction_data['transaction_string'] = transaction_data[transaction_columns].astype(str).agg(' '.join, axis=1)
invoice_data['invoice_string'] = invoice_data[invoice_columns].astype(str).agg(' '.join, axis=1)

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction strings
transaction_vectors = vectorizer.fit_transform(transaction_data['transaction_string'])

# Transform the invoice strings
invoice_vectors = vectorizer.transform(invoice_data['invoice_string'])

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

# Find the best matches
matches = []
for transaction_idx, transaction_row in transaction_data.iterrows():
    transaction_id = transaction_row['fin_record_key']
    transaction_string = transaction_row['transaction_string']
    transaction_auth_no = transaction_row['auth_no']
    transaction_source_amount = transaction_row['source_amount']
    
    best_match_score = -1
    best_match_idx = -1
    
    for invoice_idx, invoice_row in invoice_data.iterrows():
        invoice_string = invoice_row['invoice_string']
        invoice_auth_no = invoice_row['auth_no']
        invoice_source_amount = invoice_row['amount']
        invoice_company_id = invoice_row['company_id']
        
        similarity_score = similarity_matrix[transaction_idx, invoice_idx]
        
        # Check if any condition is a match
        if (transaction_row['supplier_name'] == invoice_row['ticket_number'] and similarity_score >= thresholds['supplier_name_ticket']) or \
           (transaction_row['supplier_name'] == invoice_row['inv_number'] and similarity_score >= thresholds['supplier_name_inv']) or \
           (transaction_auth_no == invoice_auth_no and similarity_score >= thresholds['auth_no']) or \
           (abs(transaction_source_amount - invoice_source_amount) <= thresholds['source_amount']):
            
            if transaction_row['company_id'] == invoice_company_id:
                if similarity_score > best_match_score:
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    
    if best_match_idx != -1:
        invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
        transaction_values = transaction_row[transaction_columns]
        invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
        matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score))

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Transaction Values, Invoice Values, Similarity Score\n")
    for match in matches:
        transaction_id, invoice_id, transaction_values, invoice_values, similarity_score = match
        file.write(f"{transaction_id}, {invoice_id}, {transaction_values}, {invoice_values}, {similarity_score}\n")










# Calculate the cosine similarity for each column
similarity_scores = {}
for column in transaction_columns:
    vectorizer = CountVectorizer()
    transaction_vectors = vectorizer.fit_transform(transaction_data[column].astype(str))
    invoice_vectors = vectorizer.transform(invoice_data[column].astype(str))
    similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)
    similarity_scores[column] = similarity_matrix





final_match = pd.DataFrame(matches, columns=['Transaction ID', 'Invoice ID', 'Transaction Values', 'Invoice Values', 'Similarity Score'])
final_match = final_match.sort_values('Similarity Score', ascending=False)
final_match = final_match.drop_duplicates(subset='Invoice ID', keep='first')
print(final_match.head(50))







import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'auth_no']
invoice_columns = ['ticket_number', 'inv_number', 'auth_no', 'amount', 'company_id']

# Set thresholds for each condition
thresholds = {
    'supplier_name_ticket': 0.1,
    'supplier_name_inv': 0.1,
    'auth_no': 0.1,
    'source_amount': 0.2,
}

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Calculate the cosine similarity for each relevant column
similarity_scores = {}
for column in transaction_columns + invoice_columns:
    transaction_vectors = vectorizer.fit_transform(transaction_data[column].astype(str))
    invoice_vectors = vectorizer.transform(invoice_data[column].astype(str))
    similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)
    similarity_scores[column] = similarity_matrix

# Find the best matches
matches = []
matched_invoices = set()  # Set to store matched invoice IDs

for transaction_idx, transaction_row in transaction_data.iterrows():
    transaction_id = transaction_row['fin_record_key']
    transaction_auth_no = transaction_row['auth_no']
    transaction_source_amount = transaction_row['source_amount']
    
    best_match_score = -1
    best_match_idx = -1
    best_match_column = ''
    
    # Check if transaction is already matched
    if transaction_id in matched_invoices:
        continue
    
    for invoice_idx, invoice_row in invoice_data.iterrows():
        invoice_id = invoice_row['inv_unmatch_inv_id']
        
        # Skip already matched invoices
        if invoice_id in matched_invoices:
            continue
        
        invoice_auth_no = invoice_row['auth_no']
        invoice_source_amount = invoice_row['amount']
        invoice_company_id = invoice_row['company_id']
        
        similarity_scores_sum = 0
        num_matching_columns = 0
        
        for column in transaction_columns + invoice_columns:
            similarity_score = similarity_scores[column][transaction_idx, invoice_idx]
            similarity_scores_sum += similarity_score
            num_matching_columns += 1 if similarity_score >= thresholds[column] else 0
        
        average_similarity_score = similarity_scores_sum / num_matching_columns if num_matching_columns > 0 else 0
        
        # Check if all conditions are met
        if (transaction_row['supplier_name'] == invoice_row['ticket_number'] or
            transaction_row['supplier_name'] == invoice_row['supplier_name']) and \
           transaction_auth_no == invoice_auth_no and \
           abs(transaction_source_amount - invoice_source_amount) <= thresholds['source_amount'] and \
           transaction_row['company_id'] == invoice_company_id and \
           average_similarity_score >= thresholds['supplier_name_ticket']:
            
            if average_similarity_score > best_match_score:
                best_match_score = average_similarity_score
                best_match_idx = invoice_idx
                best_match_column = column
    
    if best_match_idx != -1:
        invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
        
        if invoice_id not in matched_invoices:
            transaction_values = transaction_row[transaction_columns]
            invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
            match_pattern = f"{best_match_column} - {transaction_values[best_match_column]} matched with {invoice_values[best_match_column]}"
            matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score, match_pattern))
            matched_invoices.add(invoice_id)

# Create DataFrame for matches
final_match = pd.DataFrame(matches, columns=['transaction_id', 'invoice_id', 'transaction_values', 'invoice_values', 'similarity_score', 'match_pattern'])

# Sort matches by similarity score in descending order
final_match = final_match.sort_values('similarity_score', ascending=False)

# Drop duplicate invoices to keep only the best match for each transaction
final_match = final_match.drop_duplicates(subset='invoice_id', keep='first')

# Save the final matches to a CSV file
final_match.to_csv('final_matches.csv', index=False)










# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Transaction Values, Invoice Values, Similarity Score\n")
    for match in matches:
        transaction_id, invoice_id, transaction_values, invoice_values, similarity_score = match

        # Extract specific column values
        transaction_values_string = ', '.join([str(transaction_values[col]) for col in transaction_columns])
        invoice_values_string = ', '.join([str(invoice_values[col]) for col in invoice_columns])

        file.write(f"{transaction_id}, {invoice_id}, {transaction_values_string}, {invoice_values_string}, {similarity_score}\n")

# Create a DataFrame from the matches
final_match = pd.DataFrame(matches, columns=['Transaction ID', 'Invoice ID', 'Transaction Values', 'Invoice Values', 'Similarity Score'])

# Sort the DataFrame by 'Similarity Score' in ascending order
final_match = final_match.sort_values('Similarity Score', ascending=False)

# Drop duplicate invoices, keeping only the first occurrence
final_match = final_match.drop_duplicates(subset='Invoice ID', keep='first')

# Print the first 50 rows of the final matches DataFrame
print(final_match.head(50))





# Create CountVectorizer for each column separately
vectorizers = {}
for column in transaction_columns + invoice_columns:
    vectorizers[column] = CountVectorizer()

# Fit and transform the transaction and invoice data for each column
transaction_vectors = {}
invoice_vectors = {}
for column in transaction_columns:
    transaction_vectors[column] = vectorizers[column].fit_transform(transaction_data[column])
for column in invoice_columns:
    invoice_vectors[column] = vectorizers[column].transform(invoice_data[column].astype(str))

# Calculate the cosine similarity matrix for each column
similarity_matrices = {}
for column in transaction_columns:
    similarity_matrices[column] = cosine_similarity(transaction_vectors[column], invoice_vectors[column])

for transaction_idx, transaction_row in transaction_data.iterrows():
    transaction_id = transaction_row['fin_record_key']
    transaction_values = transaction_row[transaction_columns]
    
    best_match_score = -1
    best_match_idx = -1
    
    for invoice_idx, invoice_row in invoice_data.iterrows():
        invoice_id = invoice_row['inv_unmatch_inv_id']
        invoice_values = invoice_row[invoice_columns]
        
        similarity_scores = []
        
        # Calculate similarity scores for each column
        for column in transaction_columns:
            similarity_matrix = similarity_matrices[column]
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            similarity_scores.append(similarity_score)
        
        # Check if all conditions are matched
        if all(score >= thresholds[column] for score, column in zip(similarity_scores, transaction_columns)):
            average_score = sum(similarity_scores) / len(similarity_scores)
            if average_score > best_match_score:
                best_match_score = average_score
                best_match_idx = invoice_idx
    
    if best_match_idx != -1:
        invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
        invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
        matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score))








import pandas as pd
import numpy as np

def cosine_similarity(vector1, vector2):
    dot_product = np.dot(vector1, vector2)
    norm_vector1 = np.linalg.norm(vector1)
    norm_vector2 = np.linalg.norm(vector2)
    similarity = dot_product / (norm_vector1 * norm_vector2)
    return similarity

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'auth_no']
invoice_columns = ['ticket_number', 'inv_number', 'auth_no', 'amount', 'company_id']

# Set thresholds for each condition
thresholds = {
    'supplier_name': 0.1,
    'auth_no': 0.1,
    'source_amount': 0.2,
}

# Create CountVectorizer for each column separately
vectorizers = {}
for column in transaction_columns + invoice_columns:
    vectorizers[column] = CountVectorizer()

# Fit and transform the transaction and invoice data for each column
transaction_vectors = {}
invoice_vectors = {}
for column in transaction_columns:
    transaction_vectors[column] = vectorizers[column].fit_transform(transaction_data[column])
for column in invoice_columns:
    invoice_vectors[column] = vectorizers[column].transform(invoice_data[column].astype(str))

# Calculate the cosine similarity matrix for each column
similarity_matrices = {}
for column in transaction_columns:
    transaction_values = transaction_vectors[column].toarray()
    invoice_values = invoice_vectors[column].toarray()
    similarity_matrices[column] = np.zeros((transaction_values.shape[0], invoice_values.shape[0]))
    for i in range(transaction_values.shape[0]):
        for j in range(invoice_values.shape[0]):
            similarity_matrices[column][i, j] = cosine_similarity(transaction_values[i], invoice_values[j])




import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Example data
transaction_row = {
    'supplier_name': 'ABC',
    'auth_no': '123',
    'source_amount': 100,
    'company_id': 'XYZ'
}

invoice_row = {
    'ticket_number': '123',
    'supplier_name': 'ABC',
    'auth_no': '123',
    'source_amount': 102,
    'company_id': 'XYZ'
}

thresholds = {
    'source_amount': 2,
    'supplier_name_ticket': 0.8
}

# Function to calculate match based on given conditions
def calculate_match(transaction_row, invoice_row, thresholds):
    # Check condition 1: supplier_name match
    condition_1 = (transaction_row['supplier_name'] == invoice_row['ticket_number'] or
                  transaction_row['supplier_name'] == invoice_row['supplier_name'])
    
    # Check condition 2: auth_no match
    condition_2 = transaction_row['auth_no'] == invoice_row['auth_no']
    
    # Check condition 3: source_amount difference within threshold
    condition_3 = abs(transaction_row['source_amount'] - invoice_row['source_amount']) <= thresholds['source_amount']
    
    # Check condition 4: company_id match
    condition_4 = transaction_row['company_id'] == invoice_row['company_id']
    
    # Calculate average similarity score (assuming you have the code for this)
    average_similarity_score = calculate_average_similarity_score()
    
    # Check condition 5: average_similarity_score >= supplier_name_ticket threshold
    condition_5 = average_similarity_score >= thresholds['supplier_name_ticket']
    
    # Determine match based on all conditions
    match = condition_1 and condition_2 and condition_3 and condition_4 and condition_5
    
    return match

# Calculate match based on given conditions
is_match = calculate_match(transaction_row, invoice_row, thresholds)
print(is_match)




import numpy as np
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Example data
transaction_data = {
    'supplier_name': ['ABC', 'DEF', 'GHI'],
    'auth_no': ['123', '456', '789'],
    'source_amount': [100, 200, 300],
    'company_id': ['XYZ', 'ABC', 'DEF']
}

invoice_data = {
    'ticket_number': ['123', '456', '789'],
    'supplier_name': ['ABC', 'DEF', 'XYZ'],
    'auth_no': ['123', '456', '789'],
    'source_amount': [110, 190, 310],
    'company_id': ['XYZ', 'ABC', 'DEF']
}

thresholds = {
    'source_amount': 10,
    'supplier_name_ticket': 0.8
}

# Convert data to pandas DataFrames
transaction_df = pd.DataFrame(transaction_data)
invoice_df = pd.DataFrame(invoice_data)

# Function to convert columns to n-grams
def convert_to_ngrams(df, n=2):
    ngram_columns = []
    for column in df:
        ngram_vectorizer = CountVectorizer(ngram_range=(n, n))
        ngram_matrix = ngram_vectorizer.fit_transform(df[column])
        ngram_columns.append(ngram_matrix)
    return ngram_columns

# Function to calculate cosine similarity between two matrices
def calculate_cosine_similarity(matrix1, matrix2):
    similarity = cosine_similarity(matrix1, matrix2)
    return similarity

# Function to calculate average similarity score
def calculate_average_similarity_score(transaction_matrices, invoice_matrices):
    similarity_scores = []
    for transaction_matrix, invoice_matrix in zip(transaction_matrices, invoice_matrices):
        similarity_matrix = calculate_cosine_similarity(transaction_matrix, invoice_matrix)
        similarity_scores.append(np.mean(similarity_matrix))
    average_similarity_score = np.mean(similarity_scores)
    return average_similarity_score

# Function to calculate match based on given conditions
def calculate_match(transaction_row, invoice_row, thresholds):
    # Check condition 1: supplier_name match
    condition_1 = (transaction_row['supplier_name'] == invoice_row['ticket_number'] or
                  transaction_row['supplier_name'] == invoice_row['supplier_name'])
    
    # Check condition 2: auth_no match
    condition_2 = transaction_row['auth_no'] == invoice_row['auth_no']
    
    # Check condition 3: source_amount difference within threshold
    condition_3 = abs(transaction_row['source_amount'] - invoice_row['source_amount']) <= thresholds['source_amount']
    
    # Check condition 4: company_id match
    condition_4 = transaction_row['company_id'] == invoice_row['company_id']
    
    # Convert transaction and invoice data to n-grams
    transaction_matrices = convert_to_ngrams(transaction_row)
    invoice_matrices = convert_to_ngrams(invoice_row)
    
    # Calculate average similarity score
    average_similarity_score = calculate_average_similarity_score(transaction_matrices, invoice_matrices)
    
    # Check condition 5: average_similarity_score >= supplier_name_ticket threshold
    condition_5 = average_similarity_score >= thresholds['supplier_name_ticket']
    
    # Determine match based on all conditions
    match = condition_1 and condition_2 and condition_3 and condition_4 and condition_5
    
    return match

# Calculate match based on given conditions
transaction_row = transaction_df.iloc[0]
invoice_row = invoice_df.iloc[0]
is_match = calculate_match(transaction_row, invoice_row, thresholds)
print(is_match)





import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

def calculate_cosine_similarity(table1, table2):
    # Convert the tables to numpy arrays
    table1_array = np.array(table1)
    table2_array = np.array(table2)

    # Calculate cosine similarity column-wise
    cosine_similarities = cosine_similarity(table1_array.T, table2_array.T)

    # Create a list to store the column-wise similarities
    similarities = []

    # Iterate over the columns
    for i in range(cosine_similarities.shape[0]):
        similarity_values = cosine_similarities[i]
        similarities.append(similarity_values)

    # Return the column-wise similarities
    return similarities



import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Function to calculate cosine similarity between two columns
def calculate_cosine_similarity(column1, column2):
    vec1 = column1.values.reshape(1, -1)
    vec2 = column2.values.reshape(1, -1)
    similarity = cosine_similarity(vec1, vec2)[0][0]
    return similarity

# Function to compare columns of two tables using cosine similarity
def compare_tables(table1, table2, thresholds):
    result = pd.DataFrame()

    for column1 in table1.columns:
        if column1 in table2.columns:
            column2 = table2[column1]
            similarity_score = calculate_cosine_similarity(table1[column1], column2)
            result[column1] = similarity_score

            # Check if similarity score meets the threshold for the current column
            if column1 in thresholds and similarity_score >= thresholds[column1]:
                result[column1 + '_match'] = True
            else:
                result[column1 + '_match'] = False

    return result

# Define the thresholds for each column
thresholds = {
    'source_amount': 0.9,
    'supplier_name_ticket': 0.8
}

# Assuming you have two tables named 'transaction' and 'invoice'
transaction = pd.read_csv('transaction.csv')
invoice = pd.read_csv('invoice.csv')

# Apply the conditions and calculate cosine similarity
result = compare_tables(transaction, invoice, thresholds)

# Apply additional conditions
filtered_result = result[(transaction['supplier_name'] == invoice['ticket_number'] or
                          transaction['supplier_name'] == invoice['supplier_name']) and
                         transaction['transaction_auth_no'] == invoice['invoice_auth_no'] and
                         abs(transaction['transaction_source_amount'] - invoice['invoice_source_amount']) <= thresholds['source_amount'] and
                         transaction['company_id'] == invoice['invoice_company_id'] and
                         result['supplier_name_ticket_match'] >= thresholds['supplier_name_ticket']]

print(filtered_result)





# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction columns
transaction_vectors = vectorizer.fit_transform(transaction_data[transaction_columns].astype(str).values.flatten())

# Transform the invoice columns
invoice_vectors = vectorizer.transform(invoice_data[invoice_columns].astype(str).values.flatten())

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)




https://usa.visa.com/content/dam/VCOM/regional/na/us/products/documents/vdi-nyc-and-co-case-study.pdf






# Calculate the cosine similarity matrix for each column individually
similarity_matrix = {}

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

for column in transaction_data.columns:
    # Fit and transform the transaction column
    transaction_vector = vectorizer.fit_transform(transaction_data[column].astype(str))

    # Transform the invoice column
    invoice_vector = vectorizer.transform(invoice_data[column].astype(str))

    # Calculate the cosine similarity matrix
    similarity_matrix[column] = cosine_similarity(transaction_vector, invoice_vector)












from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def convert_to_vectors(data):
    vectorizer = TfidfVectorizer()
    vectors = vectorizer.fit_transform(data)
    return vectors

def find_matching_rows(table1, table2, thresholds):
    # Convert columns of both tables to vectors
    table1_vectors = convert_to_vectors(table1)
    table2_vectors = convert_to_vectors(table2)

    # Get the number of rows in each table
    table1_rows = table1_vectors.shape[0]
    table2_rows = table2_vectors.shape[0]

    # Perform cosine similarity calculations and find matching rows
    for i in range(table1_rows):
        for j in range(table2_rows):
            transaction_row = table1[i]
            invoice_row = table2[j]
            transaction_auth_no = transaction_row['auth_no']
            invoice_auth_no = invoice_row['auth_no']
            transaction_source_amount = transaction_row['source_amount']
            invoice_source_amount = invoice_row['source_amount']
            transaction_company_id = transaction_row['company_id']
            invoice_company_id = invoice_row['company_id']
            similarity_score = cosine_similarity(table1_vectors[i], table2_vectors[j])[0][0]

            if (transaction_row['supplier_name'] == invoice_row['ticket_number'] or
                    transaction_row['supplier_name'] == invoice_row['supplier_name']) and \
                    transaction_auth_no == invoice_auth_no and \
                    abs(transaction_source_amount - invoice_source_amount) <= thresholds['source_amount'] and \
                    transaction_company_id == invoice_company_id and \
                    similarity_score >= thresholds['supplier_name_ticket']:
                print(f"Matching score: {similarity_score}")
                print(f"Row {i} in Table 1 matches Row {j} in Table 2")

# Example usage
table1 = [
    {'supplier_name': 'Apple Inc.', 'auth_no': '1234', 'source_amount': 1000, 'company_id': 'C1'},
    {'supplier_name': 'Banana Corp.', 'auth_no': '5678', 'source_amount': 2000, 'company_id': 'C2'},
    {'supplier_name': 'Carrot Ltd.', 'auth_no': '9101', 'source_amount': 1500, 'company_id': 'C3'}
]

table2 = [
    {'ticket_number': '1234', 'supplier_name': 'Apple Inc.', 'auth_no': '1234', 'source_amount': 1000, 'company_id': 'C1'},
    {'ticket_number': '5678', 'supplier_name': 'Banana Corp.', 'auth_no': '5678', 'source_amount': 2000, 'company_id': 'C2'},
    {'ticket_number': '9101', 'supplier_name': 'Carrot Ltd.', 'auth_no': '9101', 'source_amount': 1500, 'company_id': 'C3'}
]

thresholds = {
    'source_amount': 100,
    'supplier_name_ticket': 0.9
}

find_matching_rows(table1, table2, thresholds)



def find_matching_rows(table1, table2, thresholds):
    # Convert columns of both tables to vectors
    table1_vectors = convert_to_vectors([row['supplier_name'].lower() for row in table1])
    table2_vectors = convert_to_vectors([row['supplier_name'].lower() for row in table2])

    # Get the number of rows in each table
    table1_rows = table1_vectors.shape[0]
    table2_rows = table2_vectors.shape[0]

    # Perform cosine similarity calculations and find matching rows
    for i in range(table1_rows):
        for j in range(table2_rows):
            transaction_row = table1[i]
            invoice_row = table2[j]
            transaction_auth_no = transaction_row['auth_no']
            invoice_auth_no = invoice_row['auth_no']
            transaction_source_amount = transaction_row['source_amount']
            invoice_source_amount = invoice_row['source_amount']
            transaction_company_id = transaction_row['company_id']
            invoice_company_id = invoice_row['company_id']
            similarity_score = cosine_similarity(table1_vectors[i], table2_vectors[j])[0][0]

            if (transaction_row['supplier_name'].lower() == invoice_row['ticket_number'].lower() or
                    transaction_row['supplier_name'].lower() == invoice_row['supplier_name'].lower()) and \
                    transaction_auth_no == invoice_auth_no and \
                    abs(transaction_source_amount - invoice_source_amount) <= thresholds['source_amount'] and \
                    transaction_company_id == invoice_company_id and \
                    similarity_score >= thresholds['supplier_name_ticket']:
                print(f"Matching score: {similarity_score}")
                print(f"Row {i} in Table 1 matches Row {j} in Table 2")





def one_to_one_match(T5, Invoice_table):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice_table):
            return True, i + 1
    return False, "Unmatched"

def bundle_match(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None

    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):
                matching_invoices.append((Invoice, rule_index))
                total_invoice_source_amt += Invoice['inv_match_source_amt']
                match_rule = rule_index

    if total_invoice_source_amt == T5['fin_source_amt']:
        return matching_invoices, match_rule
    return [], None

def determine_match_type(matching_invoices):
    num_matching_invoices = len(matching_invoices)
    if num_matching_invoices == 1:
        return "one-to-one"
    elif num_matching_invoices > 1:
        return "bundle match"
    else:
        return "Unmatched"

# Process matches
output_rows = []
matched_invoices = []
unmatched_output_rows = []

for T5 in T5_table:
    match_found, match_rule = one_to_one_match(T5, IV_table)
    matching_invoices, bundle_rule = bundle_match(T5, IV_table)

    if match_found:
        matching_invoice, rule_index = match_found
        description = rule_descriptions.get(match_rule)
        output_row = {column: T5[column] if column in T5 else matching_invoice[column] for column in output_columns}
        output_row['Match Rule'] = rule_numbers.get(match_rule)
        output_row['description'] = description
        output_row['Match Type'] = determine_match_type([matching_invoice])
        output_rows.append(output_row)
        matched_invoices.append(matching_invoice)
    elif matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(bundle_rule)
            output_row['description'] = description
            output_row['Match Type'] = determine_match_type(matching_invoices)
            output_rows.append(output_row)
            matched_invoices.append(invoice)
    else:
        unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
        unmatched_output_rows.append(unmatched_output_row)

# Create a DataFrame from the output rows
output_df = pd.DataFrame(output_rows, columns=output_columns)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Create a DataFrame for unmatched T5 rows
unmatched_t5_df = pd.DataFrame(unmatched_output_rows, columns=unmatched_output_columns)

# Write the unmatched T5 rows to a separate CSV file
unmatched_t5_df.to_csv("unmatched_t5.csv", index=False)

# Write the output data to a CSV file
output_df.to_csv(config['output_files']['output_file'], index=False)

# Write the aggregated data to Excel
with pd.ExcelWriter(config['output_files']['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)




import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# Load the dataset
data = pd.read_csv('your_dataset.csv')

# Convert text columns into vectors using TF-IDF
text_columns = data.select_dtypes(include=['object']).columns

tfidf_vectorizer = TfidfVectorizer()
text_vectors = tfidf_vectorizer.fit_transform(data[text_columns].values.astype('U'))
text_vectors_df = pd.DataFrame(text_vectors.toarray(), columns=tfidf_vectorizer.get_feature_names())

# Convert categorical columns into vectors using TF-IDF
categorical_columns = data.select_dtypes(include=['category']).columns

for column in categorical_columns:
    cat_vectors = tfidf_vectorizer.fit_transform(data[column].values.astype('U'))
    cat_vectors_df = pd.DataFrame(cat_vectors.toarray(), columns=tfidf_vectorizer.get_feature_names())
    text_vectors_df = pd.concat([text_vectors_df, cat_vectors_df], axis=1)

# Combine the vectors with the original dataset
vectors_df = pd.concat([data.select_dtypes(include=['int64', 'float64']), text_vectors_df], axis=1)

# Print the vectorized dataset
print(vectors_df)



from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# Example strings
string1 = "I love cats"
string2 = "I adore dogs"

# Convert strings into vectors using TF-IDF
tfidf_vectorizer = TfidfVectorizer()
string_vectors = tfidf_vectorizer.fit_transform([string1, string2])
string_vectors = string_vectors.toarray()

# Compute cosine similarity between the vectors
similarity_score = cosine_similarity([string_vectors[0]], [string_vectors[1]])

# Print the similarity score
print("Similarity score:", similarity_score[0][0])












from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase and removing non-alphanumeric characters
    str1 = ''.join(ch.lower() for ch in str1 if ch.isalnum())
    str2 = ''.join(ch.lower() for ch in str2 if ch.isalnum())

    # Create a TfidfVectorizer object with character n-gram range
    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(n, n))

    # Fit and transform the strings
    tfidf_matrix = vectorizer.fit_transform([str1, str2])

    # Calculate the cosine similarity
    similarity_matrix = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])

    # Get the similarity percentage
    similarity_percentage = similarity_matrix[0][0] * 100

    return similarity_percentage

# Example strings
str1 = 'ABCD123'
str2 = '789ABCD1234'

# Set the character n-gram range
n = 1  # For individual characters

# Calculate the similarity percentage
similarity_percentage = calculate_similarity(str1, str2, n)

# Print the similarity percentage
print(f"The similarity between the strings is: {similarity_percentage:.2f}%")











def calculate_similarity_percentage(str1, str2):
    mapping = {c: i for i, c in enumerate(set(str1 + str2))}
    vec1 = [mapping[c] for c in str1]
    vec2 = [mapping[c] for c in str2]
    print('Initial Vector1',vec1)
    print('Initial Vector2',vec2)

    max_len = max(len(vec1), len(vec2))
    vec1 += [0] * (max_len - len(vec1))
    vec2 += [0] * (max_len - len(vec2))
    print(vec1)
    print(vec2)

    distance = sum(abs(a - b) for a, b in zip(vec1, vec2))
    print('distance',distance)

    max_distance = max(abs(max(vec1) - min(vec1)), abs(max(vec2) - min(vec2))) * max_len
    print('max_distance',max_distance)
    similarity_percentage = (1 - (distance / max_distance)) * 100

    return similarity_percentage

# Example usage
string1 = "3451"
string2 = "A34515"
similarity = calculate_similarity_percentage(string1, string2)
print(f"Similarity percentage: {similarity}%")





import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase and removing non-alphanumeric characters
    str1 = ''.join(ch.lower() for ch in str1 if ch.isalnum())
    str2 = ''.join(ch.lower() for ch in str2 if ch.isalnum())

    # Create a TfidfVectorizer object with character n-gram range
    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(n, n))

    # Fit and transform the strings
    tfidf_matrix = vectorizer.fit_transform([str1, str2])

    # Calculate the cosine similarity
    similarity_matrix = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])

    # Get the similarity percentage
    similarity_percentage = similarity_matrix[0][0] * 100
    return similarity_percentage


def process_data(transaction_file, invoice_file):
    transaction_data = pd.read_excel(transaction_file)
    invoice_data = pd.read_excel(invoice_file)

    count = 0
    matches = []
    matched_invoices = []

    for transaction_idx, transaction_row in transaction_data.iterrows():
        transaction_id = transaction_row['T5_RECORD_KEY']
        transaction_supplier_name = transaction_row['T5_ORIG_SUPPLIER_NM']
        transaction_source_amount = transaction_row['5_SOURCE_AMT']
        transaction_auth_no = transaction_row['T5_AUTH_NBR']
        transaction_purchase = transaction_row['PURCH_ID']
        transaction_acct = transaction_row['ACCOUNT']
        transaction_company_id = transaction_row['fin_company_id']
        transaction_D_C = transaction_row['fin_debit_credit_ind']
        best_match_score = -1
        best_match_idx = -1

        for invoice_idx, invoice_row in invoice_data.iterrows():
            invoice_string = invoice_row['invoice_string']
            invoice_ticket_number = str(invoice_row['TICKET_NUM'])
            invoice_inv_no = str(invoice_row['INVNUMBER'])
            invoice_auth_no = invoice_row['inv_authn_num']
            invoice_amount = invoice_row['MATCH_SOURCE_AMT']
            invoice_company_id = invoice_row['inv_company_id']
            invoice_acct = invoice_row['ACCOUNT']
            invoice_D_C = invoice_row['INVTYPECD']

            supp_similarity_score_tkt = calculate_similarity(transaction_supplier_name, invoice_ticket_number, 3)
            supp_similarity_score_inv = calculate_similarity(transaction_supplier_name, invoice_inv_no, 3)
            auth_no_score = calculate_similarity(transaction_auth_no, invoice_auth_no, 3)
            purd_id_score_tkt = calculate_similarity(transaction_purchase, invoice_ticket_number, 3)
            purd_id_score_inv = calculate_similarity(transaction_purchase, invoice_inv_no, 3)
            similarity_score = max(supp_similarity_score_tkt, supp_similarity_score_inv, auth_no_score, purd_id_score_inv)

            condition1 = supp_similarity_score_tkt > -thresholds['supp-similarity_score-_tkt']
            condition2 = supp_similarity_score_inv > -thresholds['supp-similarity_score-inv']

            if condition1 and condition2:
                if similarity_score > best_match_score:
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx

        if best_match_idx != -1:
            invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
            transaction_values = transaction_row[transaction_columns]
            invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
            matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score))
            count += 1
            print(count)
            matched_invoices.append(invoice_id)

    return matches, matched_invoices

# Example usage
transaction_file = 'transaction_data.xlsx'
invoice_file = 'invoice_data.xlsx'
matches, matched_invoices = process_data(transaction_file, invoice_file)














import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from multiprocessing import Pool

def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase and removing non-alphanumeric characters
    str1 = ''.join(ch.lower() for ch in str1 if ch.isalnum())
    str2 = ''.join(ch.lower() for ch in str2 if ch.isalnum())

    # Create a TfidfVectorizer object with character n-gram range
    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(n, n))

    # Fit and transform the strings
    tfidf_matrix = vectorizer.fit_transform([str1, str2])

    # Calculate the cosine similarity
    similarity_matrix = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])

    # Get the similarity percentage
    similarity_percentage = similarity_matrix[0][0] * 100
    return similarity_percentage

def process_transaction(transaction_row, invoice_data):
    transaction_id = transaction_row['T5_RECORD_KEY']
    transaction_supplier_name = transaction_row['T5_ORIG_SUPPLIER_NM']
    transaction_source_amount = transaction_row['5_SOURCE_AMT']
    transaction_auth_no = transaction_row['T5_AUTH_NBR']
    transaction_purchase = transaction_row['PURCH_ID']
    transaction_acct = transaction_row['ACCOUNT']
    transaction_company_id = transaction_row['fin_company_id']
    transaction_D_C = transaction_row['fin_debit_credit_ind']
    best_match_score = -1
    best_match_idx = -1

    for invoice_idx, invoice_row in invoice_data.iterrows():
        invoice_string = invoice_row['invoice_string']
        invoice_ticket_number = str(invoice_row['TICKET_NUM'])
        invoice_inv_no = str(invoice_row['INVNUMBER'])
        invoice_auth_no = invoice_row['inv_authn_num']
        invoice_amount = invoice_row['MATCH_SOURCE_AMT']
        invoice_company_id = invoice_row['inv_company_id']
        invoice_acct = invoice_row['ACCOUNT']
        invoice_D_C = invoice_row['INVTYPECD']

        supp_similarity_score_tkt = calculate_similarity(transaction_supplier_name, invoice_ticket_number, 3)
        supp_similarity_score_inv = calculate_similarity(transaction_supplier_name, invoice_inv_no, 3)
        auth_no_score = calculate_similarity(transaction_auth_no, invoice_auth_no, 3)
        purd_id_score_tkt = calculate_similarity(transaction_purchase, invoice_ticket_number, 3)
        purd_id_score_inv = calculate_similarity(transaction_purchase, invoice_inv_no, 3)
        similarity_score = max(supp_similarity_score_tkt, supp_similarity_score_inv, auth_no_score, purd_id_score_inv)

        condition1 = supp_similarity_score_tkt > -thresholds['supp-similarity_score-_tkt']
        condition2 = supp_similarity_score_inv > -thresholds['supp-similarity_score-inv']

        if condition1 and condition2:
            if similarity_score > best_match_score:
                best_match_score = similarity_score
                best_match_idx = invoice_idx

    if best_match_idx != -1:
        invoice_id = invoice_data.loc[best_match_idx, 'inv_unmatch_inv_id']
        transaction_values = transaction_row[transaction_columns]
        invoice_values = invoice_data.loc[best_match_idx, invoice_columns]
        return (transaction_id, invoice_id, transaction_values, invoice_values, best_match_score)
    else:
        return None

def process_data(transaction_file, invoice_file):
    transaction_data = pd.read_excel(transaction_file)
    invoice_data = pd.read_excel(invoice_file)

    # Fill empty values with "I"
    transaction_data.fillna("I", inplace=True)
    invoice_data.fillna("I", inplace=True)

    count = 0
    matches = []
    matched_invoices = []

    transaction_columns = []  # Replace with the actual transaction column names you want to extract
    invoice_columns = []  # Replace with the actual invoice column names you want to extract

    # Use multiprocessing for parallel processing
    with Pool() as pool:
        result_list = []
        for _, transaction_row in transaction_data.iterrows():
            result = pool.apply_async(process_transaction, (transaction_row, invoice_data))
            result_list.append(result)

        for result in result_list:
            match = result.get()
            if match is not None:
                transaction_id, invoice_id, transaction_values, invoice_values, best_match_score = match
                matches.append((transaction_id, invoice_id, transaction_values, invoice_values, best_match_score))
                count += 1
                print(count)
                matched_invoices.append(invoice_id)

    return matches, matched_invoices




import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import OneHotEncoder

# Sample data
table1_column = ['apple', 'banana', 'orange', 'apple']
table2_column = ['orange', 'grape', 'banana', 'apple']

# Preprocess the data
# In this example, we'll use one-hot encoding to represent the categorical data

# Create an instance of the encoder
encoder = OneHotEncoder()

# Fit and transform table1_column
table1_column_encoded = encoder.fit_transform(np.array(table1_column).reshape(-1, 1))

# Fit and transform table2_column
table2_column_encoded = encoder.fit_transform(np.array(table2_column).reshape(-1, 1))

# Iterate over each row and compute cosine similarity
for i in range(len(table1_column_encoded.toarray())):
    for j in range(len(table2_column_encoded.toarray())):
        similarity_score = cosine_similarity(
            table1_column_encoded[i], table2_column_encoded[j]
        )
        print(
            f"Cosine similarity between row {i+1} in table 1 and row {j+1} in table 2: {similarity_score[0][0]}"
        )

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def calculate_similarity(str1, str2, n):
    # Create a CountVectorizer object with character n-gram range
    vectorizer = CountVectorizer(analyzer='char', ngram_range=(n, n))

    # Fit and transform the strings
    count_matrix = vectorizer.fit_transform([str1, str2])

    # Calculate the cosine similarity
    similarity_matrix = cosine_similarity(count_matrix[0], count_matrix[1])

    # Get the similarity percentage
    similarity_percentage = similarity_matrix[0][0] * 100

    return similarity_percentage






def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase
    str1 = str1.lower()
    str2 = str2.lower()

    # Generate character n-grams for each string
    ngrams_str1 = [str1[i:i+n] for i in range(len(str1)-n+1)]
    ngrams_str2 = [str2[i:i+n] for i in range(len(str2)-n+1)]

    # Count the occurrences of each n-gram in each string
    counts_str1 = {gram: ngrams_str1.count(gram) for gram in ngrams_str1}
    counts_str2 = {gram: ngrams_str2.count(gram) for gram in ngrams_str2}

    # Calculate the dot product of the two count vectors
    dot_product = sum(counts_str1.get(gram, 0) * counts_str2.get(gram, 0) for gram in set(ngrams_str1 + ngrams_str2))

    # Calculate the Euclidean norm of each count vector
    norm_str1 = math.sqrt(sum(counts_str1.get(gram, 0) ** 2 for gram in set(ngrams_str1)))
    norm_str2 = math.sqrt(sum(counts_str2.get(gram, 0) ** 2 for gram in set(ngrams_str2)))

    # Calculate the cosine similarity
    similarity = dot_product / (norm_str1 * norm_str2) if norm_str1 * norm_str2 != 0 else 0

    return similarity*100






def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase
    str1 = str1.lower()
    str2 = str2.lower()

    # Generate character n-grams for each string
    ngrams_str1 = set(str1[i:i+n] for i in range(len(str1)-n+1))
    ngrams_str2 = set(str2[i:i+n] for i in range(len(str2)-n+1))


    # Calculate the dot product
    dot_product = len(ngrams_str1.intersection(ngrams_str2))

    # Calculate the Euclidean norms
    norm_str1 = math.sqrt(len(ngrams_str1))
    norm_str2 = math.sqrt(len(ngrams_str2))

    # Calculate the cosine similarity
    similarity = dot_product / (norm_str1 * norm_str2) if norm_str1 * norm_str2 != 0 else 0

    return similarity*100













def calculate_similarity(str1, str2, n):
    # Preprocess the strings by converting them to lowercase
    str1 = str1.lower()
    str2 = str2.lower()

    # Generate character n-grams for each string as lists
    ngrams_str1 = [str1[i:i+n] for i in range(len(str1)-n+1)]
    ngrams_str2 = [str2[i:i+n] for i in range(len(str2)-n+1)]

    # Calculate the dot product
    dot_product = sum(1 for gram in ngrams_str1 if gram in ngrams_str2)

    # Calculate the Euclidean norms
    norm_str1 = math.sqrt(len(ngrams_str1))
    norm_str2 = math.sqrt(len(ngrams_str2))

    # Calculate the cosine similarity
    similarity = dot_product / (norm_str1 * norm_str2) if norm_str1 * norm_str2 != 0 else 0

    return similarity












def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None
    rule_index = 1

    while rule_index <= len(rules) and unmatched_invoices:
        invoices_to_remove = []
        for i in range(len(unmatched_invoices)):
            invoice = unmatched_invoices[i]
            if not any(value == '' or pd.isna(value) for value in invoice.values()):
                if rules[rule_index - 1](T5, Invoice=invoice):
                    invoice_amt = float(invoice['inv_match_source_amt'])
                    remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt
                    if invoice_amt <= remaining_amt:
                        matching_invoices.append((invoice, rule_index))
                        total_invoice_source_amt += invoice_amt
                        invoices_to_remove.append(i)

        for index in sorted(invoices_to_remove, reverse=True):
            unmatched_invoices.pop(index)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

        rule_index += 1

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices



def is_empty_match(T5, Invoice):
    # Check if both T5 and Invoice values are empty
    return (T5 == '') and (Invoice == '')

def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None
    rule_index = 1

    while rule_index <= len(rules) and unmatched_invoices:
        invoices_to_remove = []
        for i in range(len(unmatched_invoices)):
            invoice = unmatched_invoices[i]
            if not is_empty_match(T5['t5_auth'], invoice['inv_auth']):
                if rules[rule_index - 1](T5, Invoice=invoice):
                    invoice_amt = float(invoice['inv_match_source_amt'])
                    remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt
                    if invoice_amt <= remaining_amt:
                        matching_invoices.append((invoice, rule_index))
                        total_invoice_source_amt += invoice_amt
                        invoices_to_remove.append(i)

        for index in sorted(invoices_to_remove, reverse=True):
            unmatched_invoices.pop(index)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

        rule_index += 1

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices











import pandas as pd

# Read the dataset from a CSV file
df = pd.read_csv('your_dataset.csv')  # Replace 'your_dataset.csv' with the actual file path

# Specify the column names
acct_column = 'AcctNumber'
rule_column = 'RuleIDs'

# Group the RuleIDs by Account Number
grouped_df = df.groupby(acct_column)[rule_column].apply(list).reset_index()

# Rename the column
grouped_df = grouped_df.rename(columns={rule_column: rule_column})

# Print the resulting DataFrame
print(grouped_df)




grouped_df['Count'] = df.groupby(acct_column)[rule_column].size().reset_index(drop=True)

# Rename the columns
grouped_df = grouped_df.rename(columns={rule_column: rule_column, 'Count': 'Count'})












import pandas as pd

# Read Excel file into pandas DataFrames
df_rules = pd.read_excel('path/to/excel/file.xlsx', sheet_name='fst_rules_mI')
df_seq = pd.read_excel('path/to/excel/file.xlsx', sheet_name='fst_rule_sequence')

# Apply transformations
df_rules['flag'] = 'Y'

df_rule_seq = df_rules.merge(df_seq, left_on='rule_no', right_on='rule_id', how='inner')

def get_category(rule_description):
    if 'Ticket' in rule_description:
        return 'Ticket'
    elif 'Invoice' in rule_description:
        return 'Invoice'
    elif 'Auth' in rule_description:
        return 'Auth'
    elif 'PNR' in rule_description:
        return 'PNR'
    else:
        return 'Company'

df_rule_seq['category'] = df_rule_seq['rule_description'].apply(get_category)

df_rule_seq_ctg = df_rule_seq[['rule_no', 'rule', 'rule_description', 'company_id', 'transaction_count', 'flag', 'category']]

df_rule_seq_ctg_group = df_rule_seq_ctg.groupby('category').agg({'transaction_count': 'max'}).reset_index()

df_rule_seq_ctg_group['sequence2'] = df_rule_seq_ctg_group['transaction_count'].rank(ascending=False)

df_rule_seq_ctg_group.sort_values('sequence2', ascending=True, inplace=True)

f_final_rule = df_rule_seq_ctg.merge(df_rule_seq_ctg_group[['category', 'sequence2']], on='category', how='inner').sort_values('sequence2')









# Load existing data if the file exists, otherwise create an empty DataFrame
if os.path.exists('transaction_counts.csv'):
    transaction_counts_df = pd.read_csv('transaction_counts.csv')
else:
    transaction_counts_df = pd.DataFrame(columns=['fin_company_id', 'Match Rule', 'Transaction Count'])

# Calculate the new transaction counts and update the DataFrame
aggregated = output_df.groupby(['fin_company_id', 'Match Rule']).size().reset_index(name='Transaction Count')
total = aggregated['Transaction Count'].sum()
aggregated = aggregated.append(pd.Series(['Total', None, total], index=aggregated.columns), ignore_index=True)

# Update the existing data or add new rows
for i, row in aggregated.iterrows():
    company_id = row['fin_company_id']
    rule_number = row['Match Rule']
    transaction_count = row['Transaction Count']

    # Check if the combination of company ID and rule number already exists in the DataFrame
    existing_row = transaction_counts_df[
        (transaction_counts_df['fin_company_id'] == company_id) &
        (transaction_counts_df['Match Rule'] == rule_number)
    ]

    if not existing_row.empty:
        # Update the existing row with the new transaction count
        transaction_counts_df.loc[existing_row.index, 'Transaction Count'] += transaction_count
    else:
        # Add a new row for the company ID and rule number with the transaction count
        new_row = pd.DataFrame([[company_id, rule_number, transaction_count]], columns=['fin_company_id', 'Match Rule', 'Transaction Count'])
        transaction_counts_df = transaction_counts_df.append(new_row, ignore_index=True)

# Save the updated data to the file
transaction_counts_df.to_csv('transaction_counts.csv', index=False)













import pytest

# Import the function to be tested (make sure the function is in the same directory or module)
from your_module import match_bundle

# Define some sample data for testing
sample_T5 = {
    'fin_source_amt': '1000.00',  # Sample 'fin_source_amt' value for T5
}

sample_invoice_table = [
    {'inv_match_source_amt': '300.00'},  # Sample invoice with 'inv_match_source_amt'
    {'inv_match_source_amt': '200.00'},  # Sample invoice with 'inv_match_source_amt'
    {'inv_match_source_amt': '400.00'},  # Sample invoice with 'inv_match_source_amt'
    {'inv_match_source_amt': '100.00'},  # Sample invoice with 'inv_match_source_amt'
]

# Define some sample rules to be used by the function
# In your actual implementation, make sure to import the rules from your module
def rule_1(T5, Invoice):
    return True

def rule_2(T5, Invoice):
    return True

# Test cases
def test_match_bundle_with_matching_invoices():
    # Test the case where there are matching invoices
    matching_invoices, match_rule = match_bundle(sample_T5, sample_invoice_table)
    assert matching_invoices != []
    assert match_rule is not None
    assert sum(float(invoice['inv_match_source_amt']) for invoice, _ in matching_invoices) == float(sample_T5['fin_source_amt'])

def test_match_bundle_with_unmatched_invoices():
    # Test the case where there are no matching invoices
    T5 = {'fin_source_amt': '10000.00'}  # A larger amount to ensure no matching invoices
    unmatched_invoices = sample_invoice_table[:]  # Make a copy of the sample_invoice_table
    matching_invoices, match_rule = match_bundle(T5, unmatched_invoices)
    assert matching_invoices == []
    assert unmatched_invoices == sample_invoice_table  # The original sample_invoice_table should not be modified

def test_match_bundle_with_custom_rules():
    # Test the case where custom rules are used
    custom_rules = [rule_1, rule_2]
    matching_invoices, match_rule = match_bundle(sample_T5, sample_invoice_table, rules=custom_rules)
    assert matching_invoices != []
    assert match_rule is not None
    assert sum(float(invoice['inv_match_source_amt']) for invoice, _ in matching_invoices) == float(sample_T5['fin_source_amt'])

def test_match_bundle_with_empty_invoice_table():
    # Test the case where the invoice table is empty
    T5 = {'fin_source_amt': '1000.00'}  # Sample T5 data
    invoice_table = []  # Empty invoice table
    matching_invoices, match_rule = match_bundle(T5, invoice_table)
    assert matching_invoices == []
    assert match_rule is None

# You can add more test cases to cover other scenarios and edge cases as needed

# Run the tests
if __name__ == '__main__':
    pytest.main()



import pytest

@pytest.fixture
def sample_invoice_table():
    # Replace this with a sample invoice table in the required format
    return []

def test_match_bundle_success(sample_invoice_table):
    # Replace the following with actual values for T5 and Invoice_table
    T5 = {'fin_source_amt': '1000'}
    Invoice_table = sample_invoice_table

    matching_invoices, match_rule = match_bundle(T5, Invoice_table)

    # Assertions
    assert len(matching_invoices) > 0
    assert match_rule is not None
    assert sum(float(invoice['inv_match_source_amt']) for invoice, _ in matching_invoices) == float(T5['fin_source_amt'])







def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None
    rule_index = 1

    while rule_index <= len(rules) and unmatched_invoices:
        invoices_to_remove = []
        for i in range(len(unmatched_invoices)):
            invoice = unmatched_invoices[i]
            if rules[rule_index - 1](T5, Invoice=invoice):
                invoice_amt = float(invoice['inv_match_source_amt'])
                remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt
                if invoice_amt <= remaining_amt:
                    # Check if the invoice number is the same for the current transaction
                    if matching_invoices and matching_invoices[0][0]['inv_number'] != invoice['inv_number']:
                        continue  # Skip this invoice, as it has a different invoice number for this transaction
                    
                    matching_invoices.append((invoice, rule_index))
                    total_invoice_source_amt += invoice_amt
                    invoices_to_remove.append(i)

        for index in sorted(invoices_to_remove, reverse=True):
            unmatched_invoices.pop(index)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

        rule_index += 1

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices







def is_empty_match(T5, Invoice):
    # Check if both T5 auth and Invoice auth are empty
    is_auth_empty = (T5['t5_auth'] == '') and (Invoice['inv_auth'] == '')
    
    # Check if both T5 ticket number and Invoice ticket number are empty
    is_ticket_empty = (T5['ticket_number'] == '') and (Invoice['ticket_number'] == '')
    
    # Return True if both auth and ticket number are empty in both T5 and Invoice
    return is_auth_empty and is_ticket_empty

def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None
    rule_index = 1

    while rule_index <= len(rules) and unmatched_invoices:
        invoices_to_remove = []
        for i in range(len(unmatched_invoices)):
            invoice = unmatched_invoices[i]
            if not is_empty_match(T5, invoice):
                if rules[rule_index - 1](T5, Invoice=invoice):
                    invoice_amt = float(invoice['inv_match_source_amt'])
                    remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt
                    if invoice_amt <= remaining_amt:
                        matching_invoices.append((invoice, rule_index))
                        total_invoice_source_amt += invoice_amt
                        invoices_to_remove.append(i)

        for index in sorted(invoices_to_remove, reverse=True):
            unmatched_invoices.pop(index)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

        rule_index += 1

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices

# Rest of the code...
# Process one-to-one matches
# Process bundle matches
# Create a DataFrame from the output rows
# Write the unmatched transactions to a separate CSV file
# Write the output data to a CSV file
# Write the aggregated data to Excel
