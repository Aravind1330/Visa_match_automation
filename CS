def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            return matching_invoices, match_rule

    return [], None


def match_bundle(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):
                matching_invoices.append((Invoice, rule_index))
                total_invoice_source_amt += float(Invoice['inv_match_source_amt'])
                break

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            return matching_invoices, match_rule

    return [], None


output_rows_one_to_one = []
unmatched_output_rows_one_to_one = []
output_rows_bundle = []
unmatched_output_rows_bundle = []
matched_invoices = []

for T5 in T5_table:
    matching_invoices, match_rule = match_one_to_one(T5, Invoice_table)
    match_type = "one-to-one"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(match_rule)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_rows_one_to_one.append(output_row)
            matched_invoices.append(invoice)

        # Remove the matched invoice from Invoice_table
        Invoice_table = [inv for inv in Invoice_table if inv not in matched_invoices]

        # Remove the matched transaction from T5_table
        T5_table = [T5_row for T5_row in T5_table if T5_row['fin_record_key'] != T5['fin_record_key']]
        unmatched_fin_record_keys.remove(T5['fin_record_key'])

        unmatched_indices = unmatched_output_df[
            (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
            (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt']) &
            (unmatched_output_df['fin_debit_credit_ind'] == T5['fin_debit_credit_ind'])
        ].index

        unmatched_output_df.drop(unmatched_indices, inplace=True)

    else:
        unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
        unmatched_output_rows_one_to_one.append(unmatched_output_row)
        unmatched_fin_record_keys.add(T5['fin_record_key'])

for T5 in T5_table:
    matching_invoices, match_rule = match_bundle(T5, Invoice_table)
    match_type = "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(match_rule)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_rows_bundle.append(output_row)
            matched_invoices.append(invoice)

        # Remove the matched invoices from Invoice_table
        Invoice_table = [inv for inv in Invoice_table if inv not in matched_invoices]

        # Remove the matched transaction from T5_table
        T5_table = [T5_row for T5_row in T5_table if T5_row['fin_record_key'] != T5['fin_record_key']]
        unmatched_fin_record_keys.discard(T5['fin_record_key'])

        unmatched_indices = unmatched_output_df[
            (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
            (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
        ].index

        unmatched_output_df.drop(unmatched_indices, inplace=True)

    else:
        unmatched_output_rows_bundle.append(T5)












import re

def is_valid_rule(T5, Invoice):
    authno_T5 = T5['authno']
    authno_Invoice = Invoice['authno']

    if authno_T5.isalpha() and authno_Invoice.isalpha():
        return False  # Both values are alphabetic, so not a valid match
    else:
        return authno_T5 == authno_Invoice

def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None
    invoices_to_remove = []

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if (
                rule(T5, Invoice=Invoice)
                and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt'])
                and is_valid_rule(T5, Invoice)  # Check if the rule is valid
            ):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                invoices_to_remove.append(Invoice)
                break

    for invoice in invoices_to_remove:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None


def match_bundle(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None
    invoices_to_remove = []

    for Invoice in Invoice_table:
        for rule_index, rule in enumerate(rules, start=1):
            if (
                rule(T5, Invoice=Invoice)
                and is_valid_rule(T5, Invoice)  # Check if the rule is valid
            ):
                matching_invoices.append((Invoice, rule_index))
                total_invoice_source_amt += float(Invoice['inv_match_source_amt'])
                invoices_to_remove.append(Invoice)

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            break

    for invoice in invoices_to_remove:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None






def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for i, Invoice in enumerate(Invoice_table):
        if Invoice in matching_invoices:
            continue  # Skip already matched invoices

        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            break

    for invoice, _ in matching_invoices:
        Invoice_table.remove(invoice)

    if matching_invoices:
        return matching_invoices, match_rule
    else:
        return [], None





def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None

    for rule_index, rule in enumerate(rules, start=1):
        matched_invoices = []

        for Invoice in unmatched_invoices:
            if rule(T5, Invoice=Invoice):
                invoice_amt = float(Invoice['inv_match_source_amt'])
                remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt

                if invoice_amt <= remaining_amt:
                    matched_invoices.append((Invoice, rule_index))

        if matched_invoices:
            best_match = max(matched_invoices, key=lambda x: float(x[0]['inv_match_source_amt']))
            matching_invoices.append(best_match)
            total_invoice_source_amt += float(best_match[0]['inv_match_source_amt'])
            unmatched_invoices.remove(best_match[0])
            match_rule = rule_index

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            break

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices







def match_bundle(T5, Invoice_table):
    matching_invoices = []
    unmatched_invoices = Invoice_table[:]
    total_invoice_source_amt = 0
    match_rule = None

    for rule_index, rule in enumerate(rules, start=1):
        for i in range(len(unmatched_invoices)):
            Invoice = unmatched_invoices[i]
            if Invoice in matching_invoices:
                continue  # Skip already matched invoices

            if rule(T5, Invoice=Invoice):
                invoice_amt = float(Invoice['inv_match_source_amt'])
                remaining_amt = float(T5['fin_source_amt']) - total_invoice_source_amt

                if invoice_amt <= remaining_amt:
                    matching_invoices.append((Invoice, rule_index))
                    total_invoice_source_amt += invoice_amt

        if total_invoice_source_amt == float(T5['fin_source_amt']):
            match_rule = rule_index
            break

    if total_invoice_source_amt == float(T5['fin_source_amt']):
        return matching_invoices, match_rule
    else:
        return [], unmatched_invoices






import pandas as pd

def match_one_to_one(T5, Invoice_table):
    matching_invoices = []
    match_rule = None

    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule_index == 25 and (
                (T5['fin_orig_supplier_nm'] is None or pd.isnull(T5['fin_orig_supplier_nm'])) and
                (Invoice['inv_ticket_num'] is None or pd.isnull(Invoice['inv_ticket_num']))
            ):
                continue

            if rule(T5, Invoice=Invoice) and float(T5['fin_source_amt']) == float(Invoice['inv_match_source_amt']):
                matching_invoices.append((Invoice, rule_index))
                match_rule = rule_index
                break

        if matching_invoices:
            break

    return matching_invoices, match_rule









import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Assuming you have two DataFrames representing the tables
finrecord_df = pd.DataFrame(data={'finrecord_key': [1, 2, 3], 'column1': [...], 'column2': [...]})
invoice_df = pd.DataFrame(data={'invoice_id': [101, 102, 103], 'column1': [...], 'column2': [...]})

# Assuming you have two arrays representing the desired columns for each table
table1_columns = finrecord_df[['column1', 'column2', ...]].values
table2_columns = invoice_df[['column1', 'column2', ...]].values

similarity_matrix = cosine_similarity(table1_columns, table2_columns)

column_thresholds = {
    'column1': 0.8,
    'column2': 0.9,
    ...
}

matching_pairs = []
for i, row in enumerate(similarity_matrix):
    for j, score in enumerate(row):
        if all(score >= threshold for threshold in column_thresholds.values()):
            matching_pairs.append((i, j))

unmatched_invoice_ids = set(range(len(table2_columns)))

for pair in matching_pairs:
    finrecord_key = finrecord_df['finrecord_key'].iloc[pair[0]]  # finrecord_key from Table 1
    invoice_id = invoice_df['invoice_id'].iloc[pair[1]]  # invoice_id from Table 2
    unmatched_invoice_ids.remove(pair[1])
    print(f"Matching pair: finrecord_key={finrecord_key}, invoice_id={invoice_id}")

for unmatched_id in unmatched_invoice_ids:
    invoice_id = invoice_df['invoice_id'].iloc[unmatched_id]  # invoice_id from Table 2
    print(f"Unmatched invoice_id: {invoice_id}")







import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction.text import CountVectorizer

# Assuming you have two DataFrames representing the tables
finrecord_df = pd.DataFrame(data={'finrecord_key': [1, 2, 3], 'column1': ['text1', 'text2', 'text3'], 'column2': ['A', 'B', 'C']})
invoice_df = pd.DataFrame(data={'invoice_id': [101, 102, 103], 'column1': ['text2', 'text4', 'text1'], 'column2': ['B', 'D', 'A']})

# Text preprocessing
text_cols = ['column1']
for col in text_cols:
    finrecord_df[col] = finrecord_df[col].str.lower().replace('[^a-zA-Z0-9]', '', regex=True)
    invoice_df[col] = invoice_df[col].str.lower().replace('[^a-zA-Z0-9]', '', regex=True)

# One-hot encoding for alphanumeric columns
alphanumeric_cols = ['column2']
encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')

# Fit and transform the encoder on the combined dataset of both tables
combined_df = pd.concat([finrecord_df[alphanumeric_cols], invoice_df[alphanumeric_cols]])
encoded_features = encoder.fit_transform(combined_df)

# Split the encoded features back into separate arrays for each table
num_finrecord_rows = len(finrecord_df)
encoded_finrecord = encoded_features[:num_finrecord_rows]
encoded_invoice = encoded_features[num_finrecord_rows:]

# Assuming you have two arrays representing the desired columns for each table
table1_columns = np.concatenate((finrecord_df[text_cols].values, encoded_finrecord), axis=1)
table2_columns = np.concatenate((invoice_df[text_cols].values, encoded_invoice), axis=1)

# Calculate cosine similarity
similarity_matrix = cosine_similarity(table1_columns, table2_columns)

column_thresholds = {
    'column1': 0.8,
    'column2': 0.9,
    ...
}

matching_pairs = []
for i, row in enumerate(similarity_matrix):
    for j, score in enumerate(row):
        if all(score >= threshold for threshold in column_thresholds.values()):
            matching_pairs.append((i, j))

unmatched_invoice_ids = set(range(len(table2_columns)))

for pair in matching_pairs:
    finrecord_key = finrecord_df['finrecord_key'].iloc[pair[0]]  # finrecord_key from Table 1
    invoice_id = invoice_df['invoice_id'].iloc[pair[1]]  # invoice_id from Table 2
    unmatched_invoice_ids.remove(pair[1])
    print(f"Matching pair: finrecord_key={finrecord_key}, invoice_id={invoice_id}")

for unmatched_id in unmatched_invoice_ids:
    invoice_id = invoice_df['invoice_id'].iloc[unmatched_id]  # invoice_id from Table 2
    print(f"Unmatched invoice_id: {invoice_id}")














import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# Load your transaction and invoice data into pandas DataFrames
transaction_data = pd.read_csv('transaction_data.csv')
invoice_data = pd.read_csv('invoice_data.csv')

# Select relevant columns for matching
transaction_columns = ['supplier_name', 'source_amount', 'other_column']
transaction_features = transaction_data[transaction_columns].astype(str)
invoice_features = invoice_data['ticket_number'].astype(str).str[:5]

# Create a set to store matched invoice indices
matched_indices = set()

# Create CountVectorizer to convert text data to vectors
vectorizer = CountVectorizer()

# Fit and transform the transaction names
transaction_vectors = vectorizer.fit_transform(transaction_features['supplier_name'])

# Transform the invoice names
invoice_vectors = vectorizer.transform(invoice_features)

# Calculate the cosine similarity matrix
similarity_matrix = cosine_similarity(transaction_vectors, invoice_vectors)

# Add threshold values for each column
thresholds = {
    'supplier_name': 0.8,
    'source_amount': 0.9,
    'other_column': 0.7
}

# Find the best matches
threshold = 0.8  # Adjust the threshold based on your needs
matches = []
for transaction_idx, transaction_name in enumerate(transaction_features['supplier_name']):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx, _ in enumerate(invoice_features):
        if invoice_idx not in matched_indices:  # Check if the invoice has already been matched
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            if similarity_score > best_match_score:
                best_match_score = similarity_score
                best_match_idx = invoice_idx
    if best_match_score >= threshold:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matches.append((transaction_id, invoice_id, best_match_idx, best_match_score))
        matched_indices.add(best_match_idx)

# Display and save the matches
output_file = 'matches.csv'
with open(output_file, 'w') as file:
    file.write("Transaction ID, Invoice ID, Best Match Index, Score\n")
    for match in matches:
        file.write(f"{match[0]}, {match[1]}, {match[2]}, {match[3]}\n")
        print(f"Match found: Transaction ID {match[0]} -> Invoice ID {match[1]}, "
              f"Best Match Index: {match[2]}, Score: {match[3]}")

print(f"Matches saved to {output_file}")











matches = []
for transaction_idx, transaction_name in enumerate(transaction_features['supplier_name']):
    best_match_score = -1
    best_match_idx = -1
    for invoice_idx, _ in enumerate(invoice_features):
        if invoice_idx not in matched_indices:  # Check if the invoice has already been matched
            similarity_score = similarity_matrix[transaction_idx, invoice_idx]
            if similarity_score > best_match_score:
                # Check if the best match score meets the threshold for each column
                if (similarity_score >= thresholds['supplier_name'] and
                        float(transaction_features.iloc[transaction_idx]['source_amount']) >= thresholds['source_amount'] and
                        float(transaction_features.iloc[transaction_idx]['other_column']) >= thresholds['other_column']):
                    best_match_score = similarity_score
                    best_match_idx = invoice_idx
    if best_match_idx != -1:
        transaction_id = transaction_data.iloc[transaction_idx]['fin_record_key']
        invoice_id = invoice_data.iloc[best_match_idx]['inv_unmatch_inv_id']
        matches.append((transaction_id, invoice_id, best_match_idx, best_match_score))
        matched_indices.add(best_match_idx)








import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# Define the thresholds for each column
thresholds = {'Name': 0.8, 'Location': 0.7}

# Sample data for demonstration
data1 = {'RecordKey': [1, 2, 3, 4],
         'Name': ['John Smith', 'Jane Doe', 'Adam Johnson', 'Emily Brown'],
         'Location': ['New York', 'London', 'Paris', 'Sydney']}
data2 = {'MatchID': [5, 6, 7, 8],
         'Full Name': ['Jon Smith', 'Jane D.', 'Adam J.', 'Emily B.'],
         'Place': ['NY', 'London', 'Paris', 'Sydney']}
df1 = pd.DataFrame(data1)
df2 = pd.DataFrame(data2)

# Columns for similarity check
columns_to_check = ['Name', 'Location']

# Combine the data from both tables
combined_data = pd.concat([df1[col].astype(str) for col in columns_to_check] +
                          [df2[col].astype(str) for col in columns_to_check])

# Perform TF-IDF vectorization on the combined data
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(combined_data)

# Calculate cosine similarity between the rows of df1 and df2
similarity_matrix = cosine_similarity(tfidf_matrix[:len(df1)], tfidf_matrix[len(df1):])

# Iterate through each row of df1
for i, row1 in df1.iterrows():
    record_key = row1['RecordKey']
    
    # Find the indices where the similarity exceeds the threshold
    indices = [j for j, similarity in enumerate(similarity_matrix[i]) if similarity >= thresholds[col]]
    
    if indices:
        match_ids = df2.loc[indices, 'MatchID'].tolist()
        print(f"Record key {record_key} matches with match IDs {match_ids}.")
    else:
        print(f"No matches found for record key {record_key}.")




