# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")  # Modified lambda function to use 'Invoice' as a keyword argument
    rules.append(rule)
    rule_descriptions[i+1] = rule_description
    rule_numbers[i+1] = rule_no

# ...

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):  # Updated to use 'Invoice' as a keyword argument
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index  # Store the rule number when a match occurs
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule  # Return the matching invoices and rule number

    return [], None


# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(match_rule)  # Add the rule number to the output row
            output_row['Description'] = description
            output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)
















# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")
    rules.append(rule)
    rule_descriptions[rule_no] = rule_description  # Store rule description with rule number
    rule_numbers[i + 1] = rule_no

# ...

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_numbers[i + 1]
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule

    return [], None


# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(match_rule, '')  # Retrieve description using match_rule
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = match_rule
            output_row['Description'] = description
            output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)













# Run the command to move the files to the desired location on the C drive
subprocess.run(['cmd', '/c', 'move', output_file_path, r'file://WV730H032577/New Software/FST/output.csv'], shell=True)
subprocess.run(['cmd', '/c', 'move', unmatched_output_file_path, r'file://WV730H032577/New Software/FST/unmatched_output.csv'], shell=True)




# Move the files to the desired location on the C drive
move_output_command = f'move "{output_file_path}" "file://WV730H032577/New Software/FST/output.csv"'
move_unmatched_output_command = f'move "{unmatched_output_file_path}" "file://WV730H032577/New Software/FST/unmatched_output.csv"'

os.system(move_output_command)
os.system(move_unmatched_output_command)









import pandas as pd

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['inv_match_source_amt']
                match_rule = rule_index
                break
        if total_invoice_source_amt == T5['fin_source_amt']:
            return matching_invoices, match_rule
    return [], None

def preprocess_data(T5_table, Invoice_table):
    output_rows = []
    unmatched_output_rows = []

    for T5 in T5_table:
        matching_invoices, match_rule = match_row(T5, Invoice_table)
        if matching_invoices:
            for invoice, rule_index in matching_invoices:
                description = rule_descriptions.get(rule_index)
                output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
                output_row['Match Rule'] = rule_index  # Add the rule number to the output row
                output_row[description] = description
                output_rows.append(output_row)
        else:
            unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
            unmatched_output_rows.append(unmatched_output_row)

    output_df = pd.DataFrame(output_rows, columns=output_columns)
    unmatched_output_df = pd.DataFrame(unmatched_output_rows, columns=unmatched_output_columns)

    return output_df, unmatched_output_df




import pandas as pd
import yaml
from preprocess import match_row, preprocess_data

# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i + 1] = rule_description

# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the output columns
output_columns = config['output_columns']
unmatched_output_columns = config['unmatched_output_columns']

# Process the data
output_df, unmatched_output_df = preprocess_data(T5_table, Invoice_table)

# Check if previous matched transactions file exists
if os.path.exists('Z:/Desktop/matched_output.csv'):
    # Load previously matched transactions
    previous_matched_output_df = pd.read_csv('Z:/Desktop/matched_output.csv')
    previous_matched_transactions = previous_matched_output_df['TransactionID'].tolist()
else:
    previous_matched_transactions = []

# Filter previously matched transactions from unmatched output
unmatched_output_df = unmatched_output_df[~unmatched_output_df['TransactionID'].isin(previous_matched_transactions)]

# Update unmatched transactions with new unmatched transactions
unmatched_output_df = pd.concat([previous_unmatched_output_df, unmatched_output_df], ignore_index=True)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output.csv', index=False)
unmatched_output_df.to_csv('Z:/Desktop/unmatched_output.csv', index=False)

# Write the aggregated data to Excel
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)










# Identify the indices of matched rows
matched_indices = []
for index, row in unmatched_output_df.iterrows():
    for invoice in Invoice_table:
        if match_row(row, invoice):
            matched_indices.append(index)
            break

# Drop the matched rows from unmatched_output_df
unmatched_output_df.drop(matched_indices, inplace=True)

# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Write the updated unmatched transactions to the unmatched output file
unmatched_output_df.to_csv(unmatched_output_file, index=False)






for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_index  # Add the rule number to the output row
            output_row[description] = description
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_indices = unmatched_output_df[
                (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
                (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
            ].index
            unmatched_output_df.drop(unmatched_indices, inplace=True)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)


# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Save the updated unmatched output to the file
unmatched_output_df.to_csv('Z:/Desktop/Automation_output/Unmatched.csv', index=False)





# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"
    
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(rule_index)  # Add the rule number to the output row
            output_row['Description'] = description
            output_row['Match Type'] = match_type  # Add the match type to the output row
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_indices = unmatched_output_df[
                (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
                (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
            ].index
            unmatched_output_df.drop(unmatched_indices, inplace=True)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

# Create a DataFrame from the output rows
output_df = pd.DataFrame(output_rows, columns=output_columns + ['Match Rule', 'Description', 'Match Type'])

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output.csv', index=False)





def format_value(value):
    if isinstance(value, (int, float)):
        # Convert the numeric value to a string with the desired format
        return "{:.2f}".format(value)
    else:
        # Return the string value as it is
        return value


# Write the output data to a CSV file
output_df['NumericColumn1'] = output_df['NumericColumn1'].apply(format_number)
output_df['NumericColumn2'] = output_df['NumericColumn2'].apply(format_number)
# Repeat this for other numeric columns in your DataFrame
output_df.to_csv('Z:/Desktop/output.csv', index=False)






from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a SparkSession
spark = SparkSession.builder.getOrCreate()

# Read the rules from the CSV file
rules_df = spark.read.csv('Z:/Desktop/Rules.csv', header=True)
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in enumerate(rules_df.collect()):
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")  # Modified lambda function to use 'Invoice' as a keyword argument
    rules.append(rule)
    rule_descriptions[i+1] = rule_description
    rule_numbers[i+1] = rule_no

# Read the config file
config = yaml.safe_load(open('config.yml'))

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):  # Updated to use 'Invoice' as a keyword argument
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index  # Store the rule number when a match occurs
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule  # Return the matching invoices and rule number

    return [], None

# Process the data
output_rows = []
unmatched_output_rows = []

# Convert T5_table and Invoice_table to Spark DataFrames
T5_table_df = spark.createDataFrame(T5_table)
Invoice_table_df = spark.createDataFrame(Invoice_table)

# Process each T5 transaction
for T5 in T5_table_df.collect():
    matching_invoices, match_rule = match_row(T5, Invoice_table_df.collect())
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(rule_index)  # Add the rule number to the output row
            output_row['Description'] = description
            output_row['Match Type'] = match_type  # Add the match type to the output row
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_output_df = unmatched_output_df.filter(
                (col('fin_record_key') != T5['fin_record_key']) |
                (col('fin_source_amt') != T5['fin_source_amt'])
            )
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

# Create a DataFrame from the output rows
output_df = spark.createDataFrame(output_rows)

# Write the output data to a CSV file
output_df.write.csv('Z:/Desktop/output.csv', header=True, mode='overwrite')





for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(rule_index)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_output_df = unmatched_output_df.filter(
                (col('fin_record_key') != T5['fin_record_key']) |
                (col('fin_source_amt') != T5['fin_source_amt'])
            )
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)







def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = spark.sql.functions.sum(col('Source Amt')).alias('total_invoice_source_amt')
    match_rule = None
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index
                break

    match_condition = total_invoice_source_amt == T5['Transaction Source Amt']
    matching_invoices = matching_invoices.filter(match_condition)

    if matching_invoices:
        return matching_invoices, match_rule

    return [], None







from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql.functions import col, sum

# Create a SparkSession
spark = SparkSession.builder.getOrCreate()

# Read the rules from the CSV file
rules_df = spark.read.csv('Z:/Desktop/Rules.csv', header=True)
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in enumerate(rules_df.collect()):
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")
    rules.append(rule)
    rule_descriptions[i+1] = rule_description
    rule_numbers[i+1] = rule_no

# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the match_row function
def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = sum(col('Source Amt')).alias('total_invoice_source_amt')
    match_rule = None
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index
                break

    match_condition = total_invoice_source_amt == T5['Transaction Source Amt']
    matching_invoices = spark.createDataFrame(matching_invoices, ['Invoice', 'Rule Index']).filter(match_condition)

    if matching_invoices.count() > 0:
        return matching_invoices.collect(), match_rule

    return [], None

# Define the output columns
output_columns = config['output_columns']
unmatched_output_columns = config['unmatched_output_columns']

# Process the data
output_rows = []
unmatched_output_rows = []

# Create an empty DataFrame with the desired schema for output
output_schema = StructType([
    StructField(column, StringType(), nullable=True) for column in output_columns + ['Match Rule', 'Description', 'Match Type']
])
output_df = spark.createDataFrame([], schema=output_schema)

for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"

    if matching_invoices:
        for invoice_row in matching_invoices:
            invoice = invoice_row['Invoice']
            rule_index = invoice_row['Rule Index']
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5.columns else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(rule_index)
            output_row['Description'] = description
            output_row['Match Type'] = match_type
            output_df = output_df.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_output_df = unmatched_output_df.filter(
                ~((col('fin_record_key') == T5['fin_record_key']) &
                  (col('fin_source_amt').getItem(0) == T5['fin_source_amt']))
            )
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5.columns else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

# Write the output data to a CSV
output_df.write.csv('Z:/Desktop/output.csv', header=True, mode='overwrite')















from pyspark.sql import SparkSession
import yaml
import os

# Initialize SparkSession
spark = SparkSession.builder.getOrCreate()

# Read the rules from the CSV file
rules_df = spark.read.csv('Z:/Desktop/Rules.csv', header=True)
rules = []
rule_descriptions = {}
rule_numbers = {}
for row in rules_df.rdd.collect():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")  # Modified lambda function to use 'Invoice' as a keyword argument
    rules.append(rule)
    rule_descriptions[row['index']+1] = rule_description
    rule_numbers[row['index']+1] = rule_no


# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):  # Updated to use 'Invoice' as a keyword argument
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index  # Store the rule number when a match occurs
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule  # Return the matching invoices and rule number

    return [], None

# Define the output columns
output_columns = config['output_columns']
unmatched_output_columns = config['unmatched_output_columns']

# Process the data
output_df, unmatched_output_df = preprocess_data(T5_table, Invoice_table)

# Check if previous matched transactions file exists
if os.path.exists('Z:/Desktop/matched_output.csv'):
    # Load previously matched transactions
    previous_matched_output_df = spark.read.csv('Z:/Desktop/matched_output.csv', header=True)
    previous_matched_transactions = previous_matched_output_df.select('TransactionID').rdd.flatMap(lambda x: x).collect()
else:
    previous_matched_transactions = []


# Process each T5 transaction
output_rows = []
unmatched_output_rows = []
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(rule_index)  # Add the rule number to the output row
            output_row['Description'] = description
            output_row['Match Type'] = match_type  # Add the match type to the output row
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_output_df = unmatched_output_df.filter(
                (unmatched_output_df['fin_record_key'] != T5['fin_record_key']) |
                (unmatched_output_df['fin_source_amt'] != T5['fin_source_amt'])
            )
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

# Create a DataFrame from the output rows
output_df = spark.createDataFrame(output_rows)

# Write the output data to a CSV file
output_df.write.csv('Z:/Desktop/output.csv', header=True, mode='overwrite')





import pandas as pd
import yaml

# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i + 1] = rule_description  # Fixed index to i+1


def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable

    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):  # Updated to use 'Invoice' as a keyword argument
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['inv_match_source_amt']
                match_rule = rule_index
                # Store the rule number when a match occurs
                break

    if total_invoice_source_amt == T5['fin_source_amt']:
        return matching_invoices, match_rule
    # Return the matching invoices and rule number
    return [], None


# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the output columns
output_columns = config['output_columns']

# Define a list to store the output rows
output_rows = []

# Define a list to store the unmatched transactions
unmatched_output_columns = config['unmatched_output_columns']
unmatched_output_rows = []

unmatched_output_file = 'Z:/Desktop/Automation_output/Unmatched.csv'

# Load the existing unmatched transaction data if it exists
try:
    unmatched_output_df = pd.read_csv('Z:/Desktop/Automation_output/Unmatched.csv')
except FileNotFoundError:
    unmatched_output_df = pd.DataFrame(columns=unmatched_output_columns)

# Append the previous run unmatched transactions to unmatched_output_rows
unmatched_output_rows += unmatched_output_df.to_dict('records')

# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    match_type = "one-to-one" if len(matching_invoices) == 1 else "bundle match"

    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
            output_row['Match Rule'] = rule_numbers.get(match_rule)  # Add the rule number to the output row
            output_row['description'] = description
            output_row['Match Type'] = match_type  # Add the match type to the output row
            output_rows.append(output_row)
            # Remove the matched transaction from unmatched_output_df
            if match_type == "one-to-one":
                unmatched_indices = unmatched_output_df[
                    (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
                    (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt']) &
                    (unmatched_output_df['fin_credit_debit_ind'] == T5['fin_credit_debit_ind'])
                ].index
            else:
                unmatched_indices = unmatched_output_df[
                    (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
                    (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
                ].index
            unmatched_output_df.drop(unmatched_indices, inplace=True)
    else:
        unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
        unmatched_output_rows.append(unmatched_output_row)

# Create a DataFrame from the output rows
output_df = pd.DataFrame(output_rows, columns=output_columns)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Write the unmatched transactions to a separate CSV file
unmatched_output_df.to_csv('Z:/Desktop/unmatched_output.csv', index=False)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output.csv', index=False)

# Write the aggregated data to Excel
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
