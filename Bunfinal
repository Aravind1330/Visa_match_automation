# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")  # Modified lambda function to use 'Invoice' as a keyword argument
    rules.append(rule)
    rule_descriptions[i+1] = rule_description
    rule_numbers[i+1] = rule_no

# ...

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):  # Updated to use 'Invoice' as a keyword argument
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_index  # Store the rule number when a match occurs
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule  # Return the matching invoices and rule number

    return [], None


# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_numbers.get(match_rule)  # Add the rule number to the output row
            output_row['Description'] = description
            output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)
















# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
rule_numbers = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule_no = row['Rule No']
    rule = eval(f"lambda row, Invoice: {rule_string}")
    rules.append(rule)
    rule_descriptions[rule_no] = rule_description  # Store rule description with rule number
    rule_numbers[i + 1] = rule_no

# ...

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(row=T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['Source Amt']
                match_rule = rule_numbers[i + 1]
                break

    if total_invoice_source_amt == T5['Transaction Source Amt']:
        return matching_invoices, match_rule

    return [], None


# Process each T5 transaction
for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(match_rule, '')  # Retrieve description using match_rule
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = match_rule
            output_row['Description'] = description
            output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)













# Run the command to move the files to the desired location on the C drive
subprocess.run(['cmd', '/c', 'move', output_file_path, r'file://WV730H032577/New Software/FST/output.csv'], shell=True)
subprocess.run(['cmd', '/c', 'move', unmatched_output_file_path, r'file://WV730H032577/New Software/FST/unmatched_output.csv'], shell=True)




# Move the files to the desired location on the C drive
move_output_command = f'move "{output_file_path}" "file://WV730H032577/New Software/FST/output.csv"'
move_unmatched_output_command = f'move "{unmatched_output_file_path}" "file://WV730H032577/New Software/FST/unmatched_output.csv"'

os.system(move_output_command)
os.system(move_unmatched_output_command)









import pandas as pd

def match_row(T5, Invoice_table):
    matching_invoices = []
    total_invoice_source_amt = 0
    match_rule = None  # Initialize the match_rule variable
    for i, Invoice in enumerate(Invoice_table):
        for rule_index, rule in enumerate(rules, start=1):
            if rule(T5, Invoice=Invoice):
                matching_invoices.append((Invoice, i + 1))
                total_invoice_source_amt += Invoice['inv_match_source_amt']
                match_rule = rule_index
                break
        if total_invoice_source_amt == T5['fin_source_amt']:
            return matching_invoices, match_rule
    return [], None

def preprocess_data(T5_table, Invoice_table):
    output_rows = []
    unmatched_output_rows = []

    for T5 in T5_table:
        matching_invoices, match_rule = match_row(T5, Invoice_table)
        if matching_invoices:
            for invoice, rule_index in matching_invoices:
                description = rule_descriptions.get(rule_index)
                output_row = {column: T5[column] if column in T5 else invoice[column] for column in output_columns}
                output_row['Match Rule'] = rule_index  # Add the rule number to the output row
                output_row[description] = description
                output_rows.append(output_row)
        else:
            unmatched_output_row = {column: T5[column] if column in T5 else None for column in unmatched_output_columns}
            unmatched_output_rows.append(unmatched_output_row)

    output_df = pd.DataFrame(output_rows, columns=output_columns)
    unmatched_output_df = pd.DataFrame(unmatched_output_rows, columns=unmatched_output_columns)

    return output_df, unmatched_output_df




import pandas as pd
import yaml
from preprocess import match_row, preprocess_data

# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i + 1] = rule_description

# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the output columns
output_columns = config['output_columns']
unmatched_output_columns = config['unmatched_output_columns']

# Process the data
output_df, unmatched_output_df = preprocess_data(T5_table, Invoice_table)

# Check if previous matched transactions file exists
if os.path.exists('Z:/Desktop/matched_output.csv'):
    # Load previously matched transactions
    previous_matched_output_df = pd.read_csv('Z:/Desktop/matched_output.csv')
    previous_matched_transactions = previous_matched_output_df['TransactionID'].tolist()
else:
    previous_matched_transactions = []

# Filter previously matched transactions from unmatched output
unmatched_output_df = unmatched_output_df[~unmatched_output_df['TransactionID'].isin(previous_matched_transactions)]

# Update unmatched transactions with new unmatched transactions
unmatched_output_df = pd.concat([previous_unmatched_output_df, unmatched_output_df], ignore_index=True)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output.csv', index=False)
unmatched_output_df.to_csv('Z:/Desktop/unmatched_output.csv', index=False)

# Write the aggregated data to Excel
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)










# Identify the indices of matched rows
matched_indices = []
for index, row in unmatched_output_df.iterrows():
    for invoice in Invoice_table:
        if match_row(row, invoice):
            matched_indices.append(index)
            break

# Drop the matched rows from unmatched_output_df
unmatched_output_df.drop(matched_indices, inplace=True)

# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Write the updated unmatched transactions to the unmatched output file
unmatched_output_df.to_csv(unmatched_output_file, index=False)






for T5 in T5_table:
    matching_invoices, match_rule = match_row(T5, Invoice_table)
    if matching_invoices:
        for invoice, rule_index in matching_invoices:
            description = rule_descriptions.get(rule_index)
            output_row = {
                column: T5[column] if column in T5 else invoice[column] for column in output_columns
            }
            output_row['Match Rule'] = rule_index  # Add the rule number to the output row
            output_row[description] = description
            output_rows.append(output_row)

            # Remove the matched transaction from unmatched_output_df
            unmatched_indices = unmatched_output_df[
                (unmatched_output_df['fin_record_key'] == T5['fin_record_key']) &
                (unmatched_output_df['fin_source_amt'] == T5['fin_source_amt'])
            ].index
            unmatched_output_df.drop(unmatched_indices, inplace=True)
    else:
        unmatched_output_row = {
            column: T5[column] if column in T5 else None for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)


# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(subset=['fin_record_key'], inplace=True)

# Save the updated unmatched output to the file
unmatched_output_df.to_csv('Z:/Desktop/Automation_output/Unmatched.csv', index=False)
