valid_regions = [1, 2, 3]
T5_table = T5_table[T5_table['region id'].isin(valid_regions)]




T5_table = [row for row in T5_table if row['region id'] in valid_regions]




valid_regions = config['valid_regions']
T5_table = pd.read_excel(config['input_file_path'], dtype=str)
T5_table = T5_table[T5_table['region id'].isin(valid_regions)].to_dict(orient='records')




# Read the T5 data from an Excel file
T5_table = pd.read_excel(config['input_file_path'], dtype=str)

# Filter out rows with region id other than 1, 2, or 3
T5_table = T5_table[T5_table['region id'].isin(['1', '2', '3'])]

# Convert the remaining rows to a dictionary
T5_table = T5_table.to_dict(orient='records')











Invoice_table['inv_match_source_amt'] = Invoice_table['inv_match_source_amt'].replace('-', '')


output_df['inv_match_source_amt'] = output_df['inv_match_source_amt'].replace('', '-')



import configparser

config = configparser.ConfigParser()
config.read('config.ini')

new_output_columns = dict(config.items('output_columns'))
output_df = output_df.rename(columns=new_output_columns)





# Rename the output column names in output file
output_columns_new = [column['display_name'] for column in config['output_columns']]
output_df.columns = output_columns_new
aggregated.columns = ['Company ID & Name', 'Match Rule', 'TRF']


Name,Value
output_columns,"[
    {
        ""name"": ""Company ID & Name"",
        ""display_name"": ""Company"",
        ""required"": true
    },
    {
        ""name"": ""Match Rule"",
        ""display_name"": ""Rule"",
        ""required"": true
    },
    {
        ""name"": ""Description"",
        ""display_name"": ""Description"",
        ""required"": true
    },
    {
        ""name"": ""fin_orig_supplier_nm"",
        ""display_name"": ""Original Supplier"",
        ""required"": false
    },
    {
        ""name"": ""fin_source_amt"",
        ""display_name"": ""Source Amount"",
        ""



import datetime

# Define a function to filter rows based on date
def filter_date(table, date_col, days):
    cutoff_date = datetime.datetime.today() - datetime.timedelta(days=days)
    return table[table[date_col] < cutoff_date.strftime('%Y-%m-%d')]

# Read in the T5_table and filter out rows with dates within the last 7 working days
T5_table = pd.read_csv('Z:/Desktop/T5_table.csv')
T5_table = filter_date(T5_table, 'Date', 7)






rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i+1] = rule_description

# Define the output columns
output_columns = ['Company ID & Name', 'Match Rule', 'Description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']

# Define a list to store the output rows
output_rows = []

# Keep track of matched invoices
matched_invoices = []

# Filter T5 dataframe to remove rows with null 'fin_source_amt' column
T5_table = T5_table.dropna(subset=['fin_source_amt'])

# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    try:
        matched = False
        for i, Invoice in enumerate(Invoice_table):
            # Skip invoices that have already been matched with the same rule
            if (i, rule_index) in matched_invoices:
                continue
            matched, rule_index = match_row(T5, Invoice)
            if matched:
                description = rule_descriptions[rule_index]
                output_rows.append({
                    column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                })
                output_rows[-1]['Match Rule'] = rule_index
                output_rows[-1]['Description'] = description
                # Add the matched invoice index and rule index to the list
                matched_invoices.append((i, rule_index))
                break
    except:
        # print (f"Error processing T5: {T5}")
        error_messages.append(f"Error processing T5: {T5}")
        continue

# Create a DataFrame from the output rows and aggregate the data
output_df = pd.DataFrame(output_rows, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output2.csv', index=False)
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)




# Define a list to store the matched invoice indices
matched_invoice_indices = []

for T5 in T5_table:
    try:
        matched = False
        for i, Invoice in enumerate(Invoice_table):
            # Skip invoices that have already been matched
            if i in matched_invoice_indices:
                continue
            matched, rule_index = match_row(T5, Invoice)
            if matched:
                description = rule_descriptions[rule_index]
                output_rows.append({
                    column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                })
                output_rows[-1]['Match Rule'] = rule_index
                output_rows[-1]['Description'] = description
                # Add the matched invoice index to the list
                matched_invoice_indices.append(i)
                break
    except:
        # print (f"Error processing T5: {T5}")
        error_messages.append(f"Error processing T5: {T5}")
        continue
