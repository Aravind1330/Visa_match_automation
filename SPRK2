from pyspark.sql import SparkSession
from pyspark.sql.functions import udf
from pyspark.sql.types import StringType, BooleanType

# Create a SparkSession
spark = SparkSession.builder.appName("DataMatching").getOrCreate()

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = udf(eval(f"lambda T5, Invoice: {rule_string}"), BooleanType())
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return i+1
    return "Unmatched"

# Read in the T5 table and create a DataFrame
T5_table = spark.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").load("Z:/Downloads/Unmatched_trans_Data_1.xlsx")

# Read in the Invoice table and create a DataFrame
Invoice_table = spark.read.format("com.databricks.spark.csv").option("header", "true").option("inferSchema", "true").load("Z:/Downloads/Unmatched_Inv_Data_1.xlsx")

# Define a UDF to convert dictionary to string
dict_to_str = udf(lambda x: str(x), StringType())

# Define a UDF to add Match Rule and Description columns
add_match_rule = udf(lambda x: match_row(x.asDict(), Invoice_table.where(Invoice_table['inv_match_source_amt'] == x['fin_source_amt']).first().asDict()))

# Add Match Rule and Description columns to T5 table
T5_table = T5_table.withColumn('Match Rule', add_match_rule(T5_table)).withColumn('Description', dict_to_str(T5_table['Match Rule']))

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Define a UDF to add Description column
add_description = udf(lambda x: rule_descriptions[x] if x in rule_descriptions else '')

# Add Description column to T5 table
T5_table = T5_table.withColumn('Description', add_description(T5_table['Match Rule']))

# Write the T5 table to an Excel file
T5_table.write.format("com.databricks.spark.csv").option("header", "true").option("delimiter", "\t").mode("overwrite").save("Z:/Desktop/output2.xlsx")

# Aggregate the T5 table by Company ID & Name and Match Rule, and calculate the TRF
aggregated = T5_table.groupBy(['Company ID & Name', 'Match Rule']).count().withColumnRenamed('count', 'TRF')

# Calculate the total TRF
total = aggregated.groupBy().sum('TRF').collect()[0][0]

# Add a row for the total TRF
aggregated = aggregated.union(spark.createDataFrame([('Total', '-', total)], ['Company ID & Name', 'Match Rule', 'TRF']))

# Write the aggregated data to the second sheet of the Excel file
aggregated.write.format("com.databricks.spark.csv").option("header", "true").option







from pyspark.sql.functions import udf
from pyspark.sql.types import BooleanType, IntegerType, StringType
from pyspark.sql import SparkSession

# Define UDFs for each rule
def rule1(T5_dict, invoice_dict):
    return (
        T5_dict['fin_orig_supplier_nm'][-13:] == invoice_dict['inv_ticket_num'][-13:]
        and T5_dict['fin_account'] == invoice_dict['inv_match_account']
        and T5_dict['fin_source_amt'] == invoice_dict['inv_match_source_amt']
        and T5_dict['fin_source_currency'] == invoice_dict['inv_match_currency']
        and T5_dict['fin_date'] == invoice_dict['inv_match_date']
        and T5_dict['fin_cd_indicator'] == invoice_dict['inv_cd_indicator']
        and T5_dict['fin_rpic'] == invoice_dict['inv_match_rpic']
    )

def rule2(T5_dict, invoice_dict):
    return T5_dict['fin_orig_supplier_nm'][-12:] == invoice_dict['inv_ticket_num'][-12:] and T5_dict['fin_source_amt'] == invoice_dict['inv_match_source_amt']

def rule3(T5_dict, invoice_dict):
    return T5_dict['fin_orig_supplier_nm'][-11:] == invoice_dict['inv_ticket_num'][-11:]

# Create a SparkSession
spark = SparkSession.builder.appName("InvoiceMatching").getOrCreate()

# Read the data from Excel files into DataFrames
T5_df = spark.read.format("com.crealytics.spark.excel") \
    .option("header", "true") \
    .option("inferSchema", "true") \
    .option("treatEmptyValuesAsNulls", "true") \
    .load("Z:/Downloads/Unmatched_trans_Data_1.xlsx")

Invoice_df = spark.read.format("com.crealytics.spark.excel") \
    .option("header", "true") \
    .option("inferSchema", "true") \
    .option("treatEmptyValuesAsNulls", "true") \
    .load("Z:/Downloads/Unmatched_Inv_Data_1.xlsx")

# Define UDFs for matching rules
match_rule1_udf = udf(rule1, BooleanType())
match_rule2_udf = udf(rule2, BooleanType())
match_rule3_udf = udf(rule3, BooleanType())

# Define UDFs for rule descriptions
rule_desc1_udf = udf(lambda x: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same' if x == 1 else None, StringType())
rule_desc2_udf = udf(lambda x: 'Ticket_no_right_of_12' if x == 2 else None, StringType())

# Apply rules to each row pair and return the rule index
def match_row(T5_struct, invoice_struct):
    T5_dict = T5_struct.asDict()
    invoice_dict = invoice_struct.asDict()
    
    if match_rule1_udf(T5_dict, invoice_dict):
        return 1
    elif match_rule2_udf(T5_dict, invoice_dict):
        return 2
    elif match_rule3_udf(T5_dict, invoice_dict):
        return 3
    else:
        return None

match_row_udf = udf(match_row, IntegerType())

# Join the two DataFrames and add a column for the match rule index
joined_df = T5_df.join(Invoice_df, on='Company ID & Name', how='inner')
matched_df = joined_df.withColumn('Match Rule', match_row_udf(joined_df.T5.getItem(0), joined_df.Invoice.getItem(0)))






input_files:
  rules_file: Z:/Desktop/Rules_1.txt
  t5_file: Z:/Downloads/Unmatched_trans_Data_1.xlsx
  invoice_file: Z:/Downloads/Unmatched_Inv_Data_1.xlsx

output_file: Z:/Desktop/output2.xlsx

output_columns:
  - Company ID & Name
  - Match Rule
  - description
  - fin_orig_supplier_nm
  - fin_source_amt
  - inv_match_source_amt

rule_descriptions:
  1: Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same
  2: Ticket_no_right_of_12





import pandas as pd
import yaml

# Read the configuration file
with open("config.yaml", 'r') as f:
    config = yaml.safe_load(f)

# Read the rules from the rules file
with open(config['input_files']['rules_file'], 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i+1
    return False, "Unmatched"

# Read in the T5 and invoice data as dictionaries
T5_table = pd.read_excel(config['input_files']['t5_file'], dtype=str).to_dict(orient='records')
Invoice_table = pd.read_excel(config['input_files']['invoice_file'], dtype=str).to_dict(orient='records')

# Create an empty list for the output data
output_data = []

# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice)
        if matched:
            description = config['rule_descriptions'][rule_index]
            output_data.append({
                column: T5[column] if column in T5 else Invoice[column]
                for column in config['output_columns']
            })
            output_data[-1]['Match Rule'] = rule_index
            output_data[-1]['description'] = description
            break

# Write the output data to an Excel file
output_columns = ['Company ID & Name', 'Match Rule', 'description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt']
output_df = pd.DataFrame(output_data, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated





output_df = pd.DataFrame(output_data, columns=config['output_columns'])



# Create a new DataFrame without the last 2 columns
output_df_new = output_df.iloc[:, :-2]

# Write the new DataFrame to a new Excel file
with pd.ExcelWriter(config['output_file_no_last_2_cols']) as writer:
    output_df_new.to_excel(writer, sheet_name='Output', index=False)






def match_row(T5, Invoice_table):
    for i, rule in enumerate(rules):
        for j, Invoice in enumerate(Invoice_table):
            if rule(T5, Invoice):
                # Check if the invoice ID has already been used
                if Invoice['Invoice ID'] not in used_invoice_ids:
                    # Delete the used invoice from the Invoice_table
                    del Invoice_table[j]
                    return True, i+1
    return False, "Unmatched"


# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice_table)
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
            break

# Write the output data to an Excel file
...












# Read the rules and rule descriptions from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of tuples (rule, description)
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule_components = rule_string.split(",")
        rule = eval(f"lambda row, row2: {rule_components[0]}")
        description = rule_components[1].strip()
        rules.append((rule, description))

# Define a dictionary for rule descriptions
rule_descriptions = {i+1: rule[1] for i, rule in enumerate(rules)}











rules = []
rule_descriptions = {}
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule_parts = rule_string.split("||")
        rule = eval(f"lambda row, row2: {rule_parts[0]}")
        rules.append(rule)
        rule_descriptions[len(rules)] = rule_parts[1]

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice, used_invoice_ids):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            # Check if the invoice ID has already been used
            if Invoice['Invoice ID'] not in used_invoice_ids:
                return True, i+1
    return False, "Unmatched"













import pandas as pd

# Read the rules and rule descriptions from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, split into rules and descriptions
rules = []
rule_descriptions = {}
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule_parts = rule_string.split("||", maxsplit=1)  # Split at first occurrence only
        rule = eval(f"lambda row, row2: {rule_parts[0]}")
        rules.append(rule)
        rule_descriptions[len(rules)] = rule_parts[1]

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice, used_invoice_ids):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            # Check if the invoice ID has already been used
            if Invoice['Invoice ID'] not in used_invoice_ids:
                return True, i+1
    return False, "Unmatched"

# Read in the two Excel sheets as dictionaries
T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str).to_dict(orient='records')
Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str).to_dict(orient='records')

# Create an empty list for the output data
output_data = []

# Create a list of used invoice IDs
used_invoice_ids = []

# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice, used_invoice_ids)
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
            used_invoice_ids.append(Invoice['Invoice ID'])
            break

# Write the output data to an Excel file
output_columns = ['Company ID & Name', 'Match Rule', 'description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']
output_df = pd.DataFrame(output_data, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

with pd.ExcelWriter('Z:/Desktop/output2.xlsx') as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)









import pandas as pd

# Read rules and rule descriptions from a CSV file
rules_df = pd.read_csv("Z:/Desktop/Rules.csv")
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule = eval(f"lambda row, row2: {row['rule']}")
    rules.append(rule)
    rule_descriptions[i+1] = row['description']

# Read the two Excel sheets as dataframes
T5_df = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
Invoice_df = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

# Create an empty list for the output data
output_data = []

# Create a list of used invoice IDs
used_invoice_ids = []

# Loop through each row in T5_df and find a match in Invoice_df
for _, T5 in T5_df.iterrows():
    matched = False
    for _, Invoice in Invoice_df.iterrows():
        matched, rule_index = match_row(T5, Invoice, used_invoice_ids)
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
            used_invoice_ids.append(Invoice['Invoice ID'])
            break

# Write the output data to a CSV file
output_columns = ['Company ID & Name', 'Match Rule', 'description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']
output_df = pd.DataFrame(output_data, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

with pd.ExcelWriter('Z:/Desktop/output2.xlsx') as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)









# Read the rules and descriptions from a CSV file
rules_df = pd.read_csv("path/to/rules.csv")
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule = eval(f"lambda row, row2: {row['rule']}")
    rules.append(rule)
    rule_descriptions[i+1] = row['description']










for i, T5 in T5_table.iterrows():
    matched = False
    for j, Invoice in Invoice_table.iterrows():
        matched, rule_index = match_row(T5.to_dict(), Invoice.to_dict())
        if matched:
            T5_table.at[i, 'Match Rule'] = rule_index
            Invoice_table = Invoice_table.drop(j) # Delete the matched invoice
            break # Exit the loop after the first match
            
            
            
      def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i+1
    return False, "Unmatched"







for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice, )
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
            Invoice_table.remove(Invoice) # remove matched invoice
            break





for T5 in T5_table:
    matched = False
    for index, Invoice in enumerate(Invoice_table):
        matched, rule_index = match_row(T5, Invoice, )
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})

            # Remove the matched invoice from the table
            del Invoice_table[index]
            break







# Write the output data to a CSV file
output_columns = ['Company ID & Name', 'Match Rule', 'description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']
output_data = []
used_invoice_ids = []
for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice, used_invoice_ids)
        if matched:
            description = rule_descriptions[rule_index]
            output_data.append([T5['Company ID & Name'], rule_index, description, T5['fin_orig_supplier_nm'], T5['fin_source_amt'], Invoice['inv_match_source_amt'], Invoice['inv_erp_vend_no'], Invoice['inv_po_no']])
            used_invoice_ids.append(Invoice['Invoice ID'])
            break
output_df = pd.DataFrame(output_data, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)
output_df.to_csv('Z:/Desktop/output.csv', index=False)














Read the rules and rule descriptions from a CSV file

rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
rule_string = row['Rule']
rule_description = row['Description']
rule = eval(f"lambda row, row2: {rule_string}")
rules.append(rule)
rule_descriptions[i+1] = rule_description

Modify the code that writes the output to the Excel file as follows:
Write the output data to a CSV file

output_columns = ['Company ID & Name', 'Match Rule', 'Description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']
output_data = []
for row in output_rows:
rule_index = row['Match Rule']
description = rule_descriptions[rule_index]
output_data.append({'Company ID & Name': row['Company ID & Name'], 'Match Rule': rule_index, 'Description': description, 'fin_orig_supplier_nm': row['fin_orig_supplier_nm'], 'fin_source_amt': row['fin_source_amt'], 'inv_match_source_amt': row['inv_match_source_amt'], 'inv_erp_vend_no': row['inv_erp_vend_no'], 'inv_po_no': row['inv_po_no']})
output_df = pd.DataFrame(output_data, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)
output_df.to_csv('Z:/Desktop/output2.csv', index=False)









# Read the rules and rule descriptions from a CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i+1] = rule_description

# Define the output columns
output_columns = ['Company ID & Name', 'Match Rule', 'Description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']

# Define a list to store the output rows
output_rows = []

# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    matched = False
    for Invoice in Invoice_table:
        matched, rule_index = match_row(T5, Invoice, used_invoice_ids)
        if matched:
            description = rule_descriptions[rule_index]
            output_rows.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'Description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
            used_invoice_ids.append(Invoice['Invoice ID'])
            break

# Create a DataFrame from the output rows and aggregate the data
output_df = pd.DataFrame(output_rows, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output2.csv', index=False)











def match_row(row1, row2, used_ids):
    """Match two rows using the pre-defined rules"""
    for i, rule in enumerate(rules):
        if i + 1 in used_ids:
            continue
        if rule(row1, row2):
            return True, i + 1
    
    return False, 0










for T5 in T5_table:
for i, Invoice in enumerate(Invoice_table):
matched, rule_index = match_row(T5, Invoice)
if matched:
description = rule_descriptions[rule_index]
output_rows.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'Description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})
del Invoice_table[i]
break








# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    try:
        matched = False
        for Invoice in Invoice_table:
            matched, rule_index = match_row(T5, Invoice)
            if matched:
                description = rule_descriptions[rule_index]
                output_rows.append({'Company ID & Name': T5['Company ID & Name'], 'Match Rule': rule_index, 'Description': description, 'fin_orig_supplier_nm': T5['fin_orig_supplier_nm'], 'fin_source_amt': T5['fin_source_amt'], 'inv_match_source_amt': Invoice['inv_match_source_amt'], 'inv_erp_vend_no': Invoice['inv_erp_vend_no'], 'inv_po_no': Invoice['inv_po_no']})

                break
    except:
        print(f"Error processing T5: {T5}")
        continue
