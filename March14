import pandas as pd
import multiprocessing as mp

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(row1, row2):
    for i, rule in enumerate(rules):
        if rule(row1, row2):
            return True, i+1
    return False, "Unmatched"

def match_table_row(row):
    matched = False
    for _, Invoice in Invoice_table.iterrows():
        matched, rule_index = match_row(row.to_dict(), Invoice.to_dict())
        if matched:
            return rule_index
    return "Unmatched"

T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
# Read in the second Excel sheet
Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

# Create an empty column for the match rule index
T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Create a pool of workers
pool = mp.Pool(mp.cpu_count())

# Apply the matching function to each row in table1
results = pool.map(match_table_row, [row for _, row in T5_table.iterrows()])

# Update the match rule column with the results
T5_table['Match Rule'] = pd.Series(results)

# Create the "description" column based on the "Match Rule" column
T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

# Print the updated table
# print(T5_table)

## Convert to excel
T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the aggregated data to the second sheet of the Excel file
with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)






# Update the match rule column with the results
results = []
for _, row in T5_table.iterrows():
    result = match_table_row(row)
    results.append(result)

# Create a pool of workers
pool = mp.Pool(mp.cpu_count())


# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        # Add a check for empty rule strings
        if len(rule_string) > 0:
            rule = eval(f"lambda T5, Invoice: {rule_string}")
            rules.append(rule)



# Close the multiprocessing pool
pool.close()
pool.join()





# Define the batch size
batch_size = 10000

# Write the output in batches
with pd.ExcelWriter('Z:/Desktop/output2.xlsx') as writer:
    for i in range(0, len(T5_table), batch_size):
        batch = T5_table.iloc[i:i+batch_size]
        results = [match_table_row(row) for _, row in batch.iterrows()]
        batch['Match Rule'] = pd.Series(results)
        batch['description'] = batch['Match Rule'].map(rule_descriptions)
        batch.to_excel(writer, sheet_name='Sheet1', startrow=i, index=False)

# Write the aggregated data to the second sheet of the Excel file
aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)


















import pandas as pd
import multiprocessing as mp

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda T5, Invoice: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i+1
    return False, "Unmatched"

def match_table_row(df_chunk):
    matched = False
    results = []
    for _, row in df_chunk.iterrows():
        for _, Invoice in Invoice_table.iterrows():
            matched, rule_index = match_row(row.to_dict(), Invoice.to_dict())
            if matched:
                results.append(rule_index)
                break
        else:
            results.append("Unmatched")
    return results

# Set the chunk size
chunksize = 10000

# Read in the Excel sheets in chunks
T5_chunks = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str, chunksize=chunksize)
Invoice_chunks = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str, chunksize=chunksize)

# Create an empty column for the match rule index
T5_table = pd.concat(T5_chunks)
T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Create a pool of workers
pool = mp.Pool(mp.cpu_count())

# Apply the matching function to each row in table1
results = []
for i, df_chunk in enumerate(T5_table.groupby(T5_table.index // chunksize)):
    results_chunk = pool.apply_async(match_table_row, args=(df_chunk[1],))
    results.append(results_chunk)

# Get the results from the pool and combine them
results_combined = []
for results_chunk in results:
    results_combined.extend(results_chunk.get())

# Update the match rule column with the results
T5_table['Match Rule'] = pd.Series(results_combined)

# Create the "description" column based on the "Match Rule" column
T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

# Print the updated table
# print(T5_table)

## Convert to excel
T5_table.to




# Create a pool of workers
pool = mp.Pool(mp.cpu_count())

# Apply the matching function to each row in table1
results = pool.map(match_table_row, [row for _, row in T5_table.iterrows()])







# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        try:
            if rule(T5, Invoice):
                return True, i+1
        except IndexError:
            # Handle the index out of range error
            print(f"Index out of range: T5={T5}, Invoice={Invoice}")
            continue
    return False, "Unmatched"











import pandas as pd
import multiprocessing

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(row1, row2):
    for i, rule in enumerate(rules):
        if rule(row1, row2):
            return True, i+1
    return False, "Unmatched"

def process_rows(T5_rows, Invoice_table):
    matched_rows = []
    for i, T5 in T5_rows.iterrows():
        for j, Invoice in Invoice_table.iterrows():
            matched, rule_index = match_row(T5.to_dict(), Invoice.to_dict())
            if matched:
                T5.at['Match Rule'] = rule_index
                matched_rows.append(T5)
                break
        else:
            T5.at['Match Rule'] = "Unmatched"
            matched_rows.append(T5)
    return pd.concat(matched_rows, axis=1).T

if __name__ == '__main__':
    T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
    # Read in the second Excel sheet
    Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

    # Create an empty column for the match rule index
    T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

    # Split the T5 table into chunks to be processed by multiple processes
    num_processes = 4
    chunk_size = len(T5_table) // num_processes
    T5_chunks = [T5_table.iloc[i:i + chunk_size] for i in range(0, len(T5_table), chunk_size)]

    # Create a multiprocessing pool and apply the process_rows function to each chunk of the T5 table
    with multiprocessing.Pool(num_processes) as pool:
        results = pool.starmap(process_rows, [(chunk, Invoice_table) for chunk in T5_chunks])

    # Concatenate the results from each chunk and create the "description" column based on the "Match Rule" column
    T5_table = pd.concat(results)
    rule_descriptions = {
        1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
        2: 'Ticket_no_right_of_12'
    }
    T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

    # Write the updated table to Excel
    T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

    # Aggregate the data by company and match rule, and write to the second sheet of the
















import pandas as pd
from multiprocessing import Pool

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(row1, row2):
    for i, rule in enumerate(rules):
        if rule(row1, row2):
            return True, i+1
    return False, "Unmatched"

def match_rows(T5, Invoice):
    matched, rule_index = match_row(T5.to_dict(), Invoice.to_dict())
    return matched, rule_index

if __name__ == '__main__':
    T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
    # Read in the second Excel sheet
    Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

    # Create an empty column for the match rule index
    T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

    # Create a pool of worker processes
    pool = Pool()

    # Loop through each row in table1 and find a match in table2 using multiprocessing
    results = []
    for i, T5 in T5_table.iterrows():
        for j, Invoice in Invoice_table.iterrows():
            result = pool.apply_async(match_rows, args=(T5, Invoice))
            results.append(result)

    # Retrieve the results from the worker processes and update the table
    for i, result in enumerate(results):
        matched, rule_index = result.get()
        if matched:
            T5_table.at[i//len(Invoice_table), 'Match Rule'] = rule_index

    # Define rule descriptions
    rule_descriptions = {
        1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
        2: 'Ticket_no_right_of_12'
    }

    # Create the "description" column based on the "Match Rule" column
    T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

    # Print the updated table
    # print(T5_table)

    ## Convert to excel
    T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

    aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
    total = aggregated['TRF'].sum()
    aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

    # Write the aggregated data to the second sheet of the Excel file
    with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
        aggregated.to_excel(writer, sheet_name='Aggregated', index=False)















import pandas as pd
from multiprocessing import Pool

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = [eval(f"lambda row, row2: {rule_string.strip()}") for rule_string in rule_strings if rule_string.strip()]

def match_row(row1, row2):
    for i, rule in enumerate(rules):
        if rule(row1, row2):
            return i+1
    return "Unmatched"

def match_rows(T5, Invoice):
    return match_row(T5.to_dict(), Invoice.to_dict())

if __name__ == '__main__':
    T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
    Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

    T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

    pool = Pool()

    # Use list comprehension instead of nested loop to create a list of arguments for match_rows
    results = [pool.apply_async(match_rows, args=(T5, Invoice)) for T5 in T5_table.itertuples() for Invoice in Invoice_table.itertuples()]

    # Create a list of match rule indices
    match_rule_indices = [result.get() for result in results]

    # Update the "Match Rule" column with the match rule indices
    T5_table['Match Rule'] = match_rule_indices

    # Define rule descriptions
    rule_descriptions = {
        1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
        2: 'Ticket_no_right_of_12'
    }

    # Create the "description" column based on the "Match Rule" column
    T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

    # Write the updated table to a CSV file
    T5_table.to_csv("Z:/Desktop/output2.csv", index=False)

    # Calculate and write the aggregated data to a CSV file
    aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
    total = aggregated['TRF'].sum()
    aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)
    aggregated.to_csv("Z:/Desktop/output2_aggregated.csv", index=False)
