import pandas as pd
import multiprocessing

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i+1
    return False, "Unmatched"

T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
# Read in the second Excel sheet
Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

# Create an empty column for the match rule index
T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

# Define a function to apply the match_row function to each row pair
def process_row(i, T5, Invoice):
    matched, rule_index = match_row(T5, Invoice)
    return i, rule_index

# Create a pool of worker processes
num_processes = multiprocessing.cpu_count()
pool = multiprocessing.Pool(processes=num_processes)

# Loop through each row in table1 and find a match in table2
results = []
for i, T5 in T5_table.iterrows():
    for j, Invoice in Invoice_table.iterrows():
        results.append(pool.apply_async(process_row, args=(i, T5.to_dict(), Invoice.to_dict())))

# Get the results from the worker processes
for result in results:
    i, rule_index = result.get()
    if T5_table.at[i, 'Match Rule'] == "Unmatched":
        T5_table.at[i, 'Match Rule'] = rule_index

# Close the pool of worker processes
pool.close()

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Create the "description" column based on the "Match Rule" column
T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

# Print the updated table
# print(T5_table)

## Convert to excel
T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the aggregated data to the second sheet of the Excel file
with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)












import pandas as pd
import multiprocessing

if __name__ == '__main__':
    # Read the rules from a text file
    with open("Z:/Desktop/Rules_1.txt", 'r') as f:
        rule_strings = f.readlines()

    # Remove new line characters and empty lines, and convert to list of functions
    rules = []
    for rule_string in rule_strings:
        rule_string = rule_string.strip()
        if rule_string:
            rule = eval(f"lambda row, row2: {rule_string}")
            rules.append(rule)

    # Define a function to apply the rules to each row pair and return the rule index
    def match_row(T5, Invoice):
        for i, rule in enumerate(rules):
            if rule(T5, Invoice):
                return True, i+1
        return False, "Unmatched"

    T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
    # Read in the second Excel sheet
    Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

    # Create an empty column for the match rule index
    T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

    # Define a function to apply the match_row function to each row pair
    def process_row(i, T5, Invoice):
        matched, rule_index = match_row(T5, Invoice)
        return i, rule_index

    # Loop through each row in table1 and find a match in table2
    results = []
    try:
        # Create a pool of worker processes
        num_processes = multiprocessing.cpu_count()
        pool = multiprocessing.Pool(processes=num_processes)

        for i, T5 in T5_table.iterrows():
            for j, Invoice in Invoice_table.iterrows():
                results.append(pool.apply_async(process_row, args=(i, T5.to_dict(), Invoice.to_dict())))

        # Get the results from the worker processes
        for result in results:
            i, rule_index = result.get()
            if T5_table.at[i, 'Match Rule'] == "Unmatched":
                T5_table.at[i, 'Match Rule'] = rule_index

    finally:
        # Close the pool of worker processes
        pool.close()
        pool.join()

    # Define rule descriptions
    rule_descriptions = {
        1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
        2: 'Ticket_no_right_of_12'
    }

    # Create the "description" column based on the "Match Rule" column
    T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

    # Print the updated table
    # print(T5_table)

    ## Convert to excel
    T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

    aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
    total = aggregated['TRF'].sum()
    aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

    # Write the aggregated data to the second sheet of the Excel file
    with pd.ExcelWriter('











import pandas as pd
from multiprocessing import Pool

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(args):
    i, T5, Invoice = args
    for j, rule in enumerate(rules):
        if rule(T5, Invoice):
            return i, j+1
    return i, 0

T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
# Read in the second Excel sheet
Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

# Create an empty column for the match rule index
T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

# Define the number of processes to use
num_processes = 4

# Create a pool of worker processes
pool = Pool(num_processes)

# Define the row pairs to match
row_pairs = [(i, T5.to_dict(), Invoice.to_dict()) for i, T5 in T5_table.iterrows() for j, Invoice in Invoice_table.iterrows()]

# Apply the rules to each row pair in parallel using the worker processes
results = pool.map(match_row, row_pairs)

# Update the match rule index in the T5 table
for i, rule_index in results:
    if rule_index != 0:
        T5_table.at[i, 'Match Rule'] = rule_index

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Create the "description" column based on the "Match Rule" column
T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

# Print the updated table
# print(T5_table)

## Convert to excel
T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the aggregated data to the second sheet of the Excel file
with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)








import pandas as pd
from multiprocessing import Pool

# Read the rules from a text file
with open("Z:/Desktop/Rules_1.txt", 'r') as f:
    rule_strings = f.readlines()

# Remove new line characters and empty lines, and convert to list of functions
rules = []
for rule_string in rule_strings:
    rule_string = rule_string.strip()
    if rule_string:
        rule = eval(f"lambda row, row2: {rule_string}")
        rules.append(rule)

# Define a function to apply the rules to each row pair and return the rule index
def match_row(args):
    i, T5, Invoice = args
    for j, rule in enumerate(rules):
        if rule(T5, Invoice):
            return i, j+1
    return i, 0

T5_table = pd.read_excel('Z:/Downloads/Unmatched_trans_Data_1.xlsx', dtype=str)
# Read in the second Excel sheet
Invoice_table = pd.read_excel('Z:/Downloads/Unmatched_Inv_Data_1.xlsx', dtype=str)

# Create an empty column for the match rule index
T5_table['Match Rule'] = pd.Series(["Unmatched"]*len(T5_table))

# Define the number of processes to use
num_processes = 4

# Define row pair batches
batch_size = 100
batch_list = [(i, T5.to_dict(), Invoice.to_dict()) for i, T5 in T5_table.iterrows() for j, Invoice in Invoice_table.iterrows()]
batches = [batch_list[i:i+batch_size] for i in range(0, len(batch_list), batch_size)]

# Create a pool of worker processes
pool = Pool(num_processes)

# Apply the rules to each batch of row pairs in parallel using the worker processes
for batch in batches:
    results = pool.map(match_row, batch)

    # Update the match rule index in the T5 table
    for i, rule_index in results:
        if rule_index != 0:
            T5_table.at[i, 'Match Rule'] = rule_index

# Define rule descriptions
rule_descriptions = {
    1: 'Ticket_no_right_of_13, Acct_no, Amount, Currency, Date, C&D indicator, RPIC are same',
    2: 'Ticket_no_right_of_12'
}

# Create the "description" column based on the "Match Rule" column
T5_table['description'] = T5_table['Match Rule'].map(rule_descriptions)

# Print the updated table
# print(T5_table)

## Convert to excel
T5_table.to_excel("Z:/Desktop/output2.xlsx", index=False)

aggregated = T5_table.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the aggregated data to the second sheet of the Excel file
with pd.ExcelWriter('Z:/Desktop/output2.xlsx', mode='a') as writer:
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)
