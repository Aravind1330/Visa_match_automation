# Define the bundle match rule
def bundle_match(row, rows):
    # Get the transaction amount
    transaction_amt = row['fin_source_amt']
    
    # Filter the rows to include only the ones with the same auth/ticket number
    matching_rows = rows[(rows['inv_auth_no'] == row['inv_auth_no']) | (rows['inv_ticket_num'] == row['inv_ticket_num'])]
    
    # Calculate the sum of the invoice amounts
    invoice_amt_sum = matching_rows['inv_match_source_amt'].sum()
    
    # Check if the sum of invoice amounts matches the transaction amount
    return invoice_amt_sum == transaction_amt

# Define the output columns
output_columns = ['Company ID & Name', 'Match Rule', 'Description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no', 'inv_auth_no', 'inv_ticket_num']

# Define a list to store the output rows
output_rows = []

# Keep track of matched invoices
matched_invoices = []

# Filter T5 dataframe to remove rows with null 'fin_source_amt' column
T5_table = T5_table.dropna(subset=['fin_source_amt'])

# Loop through each row in table1 and find a match in table2
for T5 in T5_table:
    try:
        # Filter the invoice table to include only the ones that have not been matched
        unmatched_invoices = Invoice_table[~Invoice_table.index.isin(matched_invoices)]
        
        # Group the invoices by auth/ticket number and apply the bundle match rule
        groups = unmatched_invoices.groupby(['inv_auth_no', 'inv_ticket_num'])
        for _, group in groups:
            if bundle_match(T5, group):
                output_rows.append({
                    column: T5[column] if column in T5 else group.iloc[0][column] for column in output_columns
                })
                output_rows[-1]['Match Rule'] = 'Bundle Match'
                output_rows[-1]['Description'] = 'Bundle of invoices matched transaction'
                # Add the matched invoice indexes to the list
                matched_invoices.extend(group.index)
    except:
        # print (f"Error processing T5: {T5}")
        error_messages.append(f"Error processing T5: {T5}")
        continue

# Create a DataFrame from the output rows and aggregate the data
output_df = pd.DataFrame(output_rows, columns=output_columns)
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output2.csv', index=False)
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)










import pandas as pd

rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i+1] = rule_description

# Define the output columns
output_columns = ['Company ID & Name', 'Match Rule', 'Description', 'fin_orig_supplier_nm', 'fin_source_amt', 'inv_match_source_amt', 'inv_erp_vend_no', 'inv_po_no']

# Read the previously unmatched transactions if available
try:
    unmatched_output_df = pd.read_csv('Z:/Desktop/unmatched_output.csv')
except FileNotFoundError:
    unmatched_output_df = pd.DataFrame(columns=output_columns)

# Keep track of matched invoices
matched_invoices = []

# Filter T5 dataframe to remove rows with null 'fin_source_amt' column
T5_table = T5_table.dropna(subset=['fin_source_amt'])

# Loop through each row in T5_table and find a match in Invoice_table
for T5_idx, T5_row in T5_table.iterrows():
    try:
        matched = False
        for Invoice_idx, Invoice_row in Invoice_table.iterrows():
            matched, rule_index = match_row(T5_row, Invoice_row)
            if matched:
                description = rule_descriptions[rule_index]
                matched_output = {
                    column: T5_row[column] if column in T5_row else Invoice_row[column] for column in output_columns
                }
                matched_output['Match Rule'] = rule_index
                matched_output['Description'] = description
                matched_invoices.append(Invoice_idx)  # Keep track of matched invoices
                break
        if not matched:
            unmatched_output = {
                column: T5_row[column] for column in output_columns
            }
            unmatched_output['Match Rule'] = 'N/A'
            unmatched_output['Description'] = 'No match found'
            unmatched_output_df = unmatched_output_df.append(unmatched_output, ignore_index=True)
    except Exception as e:
        error_messages.append(f"Error processing T5 at index {T5_idx}: {str(e)}")
        continue

# Remove previously matched transactions from unmatched_output_df
unmatched_output_df = unmatched_output_df.drop(matched_invoices)

# Create DataFrames from the output rows for matched transactions
matched_output_df = pd.DataFrame(columns=output_columns)  # Create an empty DataFrame for matched transactions

# Aggregate the data
matched_aggregated = matched_output_df.groupby(['Company ID & Name', 'Match Rule']).size().reset_index(name='TRF')
matched_total = matched_aggregated['TRF'].sum()
matched_aggregated = matched_aggregated.append(pd.Series(['Total', '-', matched_total], index=matched_aggregated.columns), ignore_index=True)

# Write the output data to separate CSV files
matched_output_df.to_csv('Z:/Desktop/matched_output.csv', index=False)
unmatched_output_df.to_csv('Z:/Desktop/unmatched_output.csv', index=False)
matched_aggregated.to_csv('Z:/Desktop/matched_aggregated.csv', index=False)




from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a SparkSession
spark = SparkSession.builder.getOrCreate()

# Read the rules from the CSV file
rules_df = spark.read.csv('Z:/Desktop/Rules.csv', header=True, inferSchema=True)

# Convert rules_df to a list of rules
rules = []
rule_descriptions = {}
for row in rules_df.collect():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[row['Rule_ID']] = rule_description

# Define the match_row function
def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i + 1
    return False, "Unmatched"

# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the output columns
output_columns = config['output_columns']

# Define a list to store the output rows
output_rows = []

# Define a list to store the unmatched transactions
unmatched_output_columns = config['unmatched_output_columns']
unmatched_output_rows = []

unmatched_output_file = 'Z:/Desktop/unmatched_output.csv'

# Load the existing unmatched transaction data if the file exists
if os.path.isfile(unmatched_output_file):
    unmatched_output_df = spark.read.csv(unmatched_output_file, header=True, inferSchema=True)
else:
    unmatched_output_df = spark.createDataFrame([], schema=unmatched_output_columns)

# Process each T5 transaction
for T5 in T5_table:
    try:
        matched = False
        for Invoice in Invoice_table:
            matched, rule_index = match_row(T5, Invoice)
            if matched:
                description = rule_descriptions.get(rule_index, '')  # Retrieve the description using the rule_index
                output_row = {
                    column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                }
                output_row['Match Rule'] = rule_index
                output_row['Description'] = description
                output_rows.append(output_row)
                break

        if not matched:
            unmatched_output_row = {
                column: T5[column] for column in unmatched_output_columns
            }
            unmatched_output_rows.append(unmatched_output_row)

    except Exception as e:
        error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
        continue

# Create a DataFrame from the output rows
output_df = spark.createDataFrame(output_rows, output_columns)

# Aggregate the data
aggregated = output_df.groupby(['Company ID & Name', 'Match Rule']).count().withColumnRenamed('count', 'TRF')
total = aggregated.select('TRF').groupBy().sum().collect()[0][0]
aggregated = aggregated.union(spark.createDataFrame([('Total', '-', total)], aggregated.columns))

# Write the output data to a CSV file
output_df.write.csv('Z:/Desktop/output.csv', header=True, mode='overwrite')

# Remove the matched transactions from unmatched_output_df
matched_indices = unmatched_output_df.filter(
    unmatched_output_df.apply(lambda row: match_row(row, invoice) for invoice in Invoice_table)).select('index')
unmatched_output_df = unmatched_output_df.join(matched_indices, unmatched_output_df.index == matched_indices.index, 'left_anti')

# Append the new unmatched transactions to the existing unmatched_output_df
unmatched















import pandas as pd
import yaml
import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Create a SparkSession
spark = SparkSession.builder.getOrCreate()

# Read the rules from the CSV file
rules_df = pd.read_csv('Z:/Desktop/Rules.csv')
rules = []
rule_descriptions = {}
for i, row in rules_df.iterrows():
    rule_string = row['Rule']
    rule_description = row['Description']
    rule = eval(f"lambda row, row2: {rule_string}")
    rules.append(rule)
    rule_descriptions[i+1] = rule_description  # Fixed index to i+1

def match_row(T5, Invoice):
    for i, rule in enumerate(rules):
        if rule(T5, Invoice):
            return True, i+1
    return False, "Unmatched"

# Read the config file
with open('config.yml', 'r') as f:
    config = yaml.safe_load(f)

# Define the output columns
output_columns = config['output_columns']

# Define a list to store the output rows
output_rows = []

# Define a list to store the unmatched transactions
unmatched_output_columns = config['unmatched_output_columns']
unmatched_output_rows = []

unmatched_output_file = 'Z:/Desktop/unmatched_output.csv'

# Load the existing unmatched transaction data if the file exists
if os.path.isfile(unmatched_output_file):
    unmatched_output_df = spark.read.csv(unmatched_output_file, header=True)
else:
    unmatched_output_df = spark.createDataFrame([], unmatched_output_columns)

# Load T5 and Invoice data (replace with your own code to load the data into Spark DataFrames)
T5_table = spark.read.csv('T5.csv', header=True)
Invoice_table = spark.read.csv('Invoice.csv', header=True)

# Process each T5 transaction
for T5 in T5_table.rdd.toLocalIterator():
    try:
        matched = False
        for Invoice in Invoice_table.rdd.toLocalIterator():
            matched, rule_index = match_row(T5, Invoice)
            if matched:
                description = rule_descriptions.get(rule_index, '')  # Retrieve the description using the rule_index
                output_row = {
                    column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                }
                output_row['Match Rule'] = rule_index
                output_row['Description'] = description
                output_rows.append(output_row)
                break

        if not matched:
            unmatched_output_row = {
                column: T5[column] for column in unmatched_output_columns
            }
            unmatched_output_rows.append(unmatched_output_row)

    except Exception as e:
        error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
        continue

# Create a DataFrame from the output rows
output_df = pd.DataFrame(output_rows, columns=output_columns)
output_df = spark.createDataFrame(output_df)

# Aggregate the data
aggregated = output_df.groupBy(['Company ID & Name', 'Match Rule']).count().withColumnRenamed('count', 'TRF')
total = aggregated.agg({'TRF': 'sum'}).collect()[0][0]
aggregated = aggregated.union(spark.createDataFrame([['Total', '-', total]], aggregated.columns))

# Write the output data to a CSV file
output_df.write.csv('Z:/Desktop/output.csv', header=True, mode='overwrite')

# Remove the matched



# Update the "Reason" column based on conditions
unmatched_output_df.loc[unmatched_output_df['Ticket'].isna() & unmatched_output_df['Auth No'].isna(), 'Reason'] = 'Both Ticket and Auth No Empty'
unmatched_output_df.loc[unmatched_output_df['Ticket'].isna() & unmatched_output_df['Auth No'].notna(), 'Reason'] = 'No Ticket Number'
unmatched_output_df.loc[unmatched_output_df['Ticket'].notna() & unmatched_output_df['Auth No'].isna(), 'Reason'] = 'No Auth No'
unmatched_output_df.loc[unmatched_output_df['Ticket'] == 0 | unmatched_output_df['Auth No'] == 0, 'Reason'] = 'Improper Auth No or Ticket Number'


















output_columns:
  - Company ID & Name
  - Ticket
  - Auth No
  - Reason

unmatched_output_columns:
  - Company ID & Name
  - Ticket
  - Auth No

reason_conditions:
  - condition: 'Ticket.isna() and Auth No.isna()'
    reason: 'Both Ticket and Auth No Empty'
  - condition: 'Ticket.isna() and Auth No.notna()'
    reason: 'No Ticket Number'
  - condition: 'Ticket.notna() and Auth No.isna()'
    reason: 'No Auth No'
  - condition: 'Ticket == 0 or Auth No == 0'
    reason: 'Improper Auth No or Ticket Number'

output_file: 'Z:/Desktop/output.xlsx'
unmatched_output_file: 'Z:/Desktop/unmatched_output.csv'









# ID & Name', 'Match Rule']).size().reset_index(name='TRF')
total = aggregated['TRF'].sum()
aggregated = aggregated.append(pd.Series(['Total', '-', total], index=aggregated.columns), ignore_index=True)

# Update the Reason column based on conditions
reason_conditions = config['reason_conditions']
for condition in reason_conditions:
    condition_str = condition['condition']
    reason = condition['reason']
    condition_func = lambda row: literal_eval(condition_str)
    output_df.loc[condition_func(output_df), 'Reason'] = reason

# Write the output data to a CSV file
output_df.to_csv('Z:/Desktop/output.csv', index=False)

# Remove the matched transactions from unmatched_output_df
matched_indices = unmatched_output_df[
    unmatched_output_df.apply(lambda row: any(match_row(row, invoice) for invoice in Invoice_table), axis=1)
].index
unmatched_output_df.drop(matched_indices, inplace=True)

# Append the new unmatched transactions to the existing unmatched_output_df
unmatched_output_df = unmatched_output_df.append(unmatched_output_rows, ignore_index=True)

# Remove duplicates from unmatched_output_df
unmatched_output_df.drop_duplicates(inplace=True)

# Write the updated unmatched transactions to the CSV file
unmatched_output_df.to_csv(unmatched_output_file, index=False)

# Write the aggregated data to Excel
with pd.ExcelWriter(config['output_file']) as writer:
    output_df.to_excel(writer, sheet_name='Output', index=False)
    aggregated.to_excel(writer, sheet_name='Aggregated', index=False)

# Add the "Reason" column
unmatched_output_df['Reason'] = ''













# Write the output data to CSV file(s) with a maximum of 900 transactions per file
output_threshold = 900
output_filename = 'Z:/Desktop/output.csv'
remaining_filename_template = 'Z:/Desktop/output_remaining_{}.csv'
output_count = len(output_df)

if output_count > output_threshold:
    # Split the output DataFrame into multiple parts
    num_files = output_count // output_threshold + 1

    for i in range(num_files):
        start_index = i * output_threshold
        end_index = (i + 1) * output_threshold

        output_df_part = output_df[start_index:end_index]
        filename = remaining_filename_template.format(i + 1)
        output_df_part.to_csv(filename, index=False)
else:
    # Write the entire output DataFrame to the output file
    output_df.to_csv(output_filename, index=False)












# Define the maximum transactions per output file
max_transactions_per_file = 900

# Split the output DataFrame into multiple files if it exceeds the maximum transactions per file
num_files = (len(output_df) - 1) // max_transactions_per_file + 1
output_filenames = ['Z:/Desktop/output{}.csv'.format(i) for i in range(1, num_files + 1)]

for i, filename in enumerate(output_filenames):
    start_idx = i * max_transactions_per_file
    end_idx = start_idx + max_transactions_per_file

    output_df_part = output_df.iloc[start_idx:end_idx]
    output_df_part.to_csv(filename, index=False)










for T5 in T5_table:
try:
matched = False
bundle_invoice_amt = 0 # Variable to store the bundled invoice amount
matching_invoices = [] # List to store matching invoices
    for Invoice in Invoice_table:
        if T5['Auth No'] == Invoice['Auth No'] or T5['Ticket No'] == Invoice['Ticket No']:
            bundle_invoice_amt += Invoice['Source Amt']  # Sum the source amount of matching invoices
            matching_invoices.append(Invoice)

    if bundle_invoice_amt == T5['Source Amt']:
        matched = True
        rule_index = 0  # Set rule index for bundle match, you can define a specific rule index if required
        description = rule_descriptions.get(rule_index, '')  # Retrieve the description using the rule_index
        output_row = {
            column: T5[column] if column in T5 else matching_invoices[0][column] for column in output_columns
        }
        output_row['Match Rule'] = rule_index
        output_row['Description'] = description
        output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

except Exception as e:
    error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
    continue
















for T5 in T5_table:
try:
matched = False
bundle_invoice_amt = 0 # Variable to store the bundled invoice amount
matching_invoices = [] # List to store matching invoices


    for Invoice in Invoice_table:
        if T5['Auth No'] == Invoice['Auth No'] or T5['Ticket No'] == Invoice['Ticket No']:
            bundle_invoice_amt += Invoice['Source Amt']  # Sum the source amount of matching invoices
            matching_invoices.append(Invoice)

    if bundle_invoice_amt == T5['Source Amt']:
        matched = True
        rule_index = 0  # Set rule index for bundle match, you can define a specific rule index if required
        description = rule_descriptions.get(rule_index, '')  # Retrieve the description using the rule_index
        output_row = {
            column: T5[column] if column in T5 else matching_invoices[0][column] for column in output_columns
        }
        output_row['Match Rule'] = rule_index
        output_row['Description'] = description
        output_rows.append(output_row)
    else:
        unmatched_output_row = {
            column: T5[column] for column in unmatched_output_columns
        }
        unmatched_output_rows.append(unmatched_output_row)

except Exception as e:
    error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
    continue
    
    
    
    
    
    
    
    
    
    
    
    
for T5 in T5_table:
    try:
        matched = False
        matching_invoices = []  # List to store matching invoices for one-to-many match
        rule_index = 0  # Default value for rule index

        for Invoice in Invoice_table:
            if (T5['Auth No'] == Invoice['Auth No'] or T5['Ticket No'] == Invoice['Ticket No']) \
                    and T5['Source Amt'] == Invoice['Source Amt']:
                matching_invoices.append(Invoice)

        if matching_invoices:
            matched = True
            description = "One-to-Many Match"
            rule_index = 1  # Set the rule index to the desired value

            for Invoice in matching_invoices:
                output_row = {
                    column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                }
                output_row['Match Rule'] = rule_index
                output_row['Description'] = description
                output_rows.append(output_row)
        else:
            unmatched_output_row = {
                column: T5[column] for column in unmatched_output_columns
            }
            unmatched_output_rows.append(unmatched_output_row)

    except Exception as e:
        error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
        continue









for T5 in T5_table:
    try:
        matched = False
        matching_invoices = []  # List to store matching invoices for one-to-many match
        rule_index = 0  # Default value for rule index

        for Invoice in Invoice_table:
            if (T5['Auth No'] == Invoice['Auth No'] or T5['Ticket No'] == Invoice['Ticket No']):
                matching_invoices.append(Invoice)

        if matching_invoices:
            invoice_source_amt_sum = sum(invoice['Source Amt'] for invoice in matching_invoices)
            if T5['Source Amt'] == invoice_source_amt_sum:
                matched = True
                description = "One-to-Many Match"
                rule_index = 1  # Set the rule index to the desired value

                for Invoice in matching_invoices:
                    output_row = {
                        column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                    }
                    output_row['Match Rule'] = rule_index
                    output_row['Description'] = description
                    output_rows.append(output_row)
        else:
            unmatched_output_row = {
                column: T5[column] for column in unmatched_output_columns
            }
            unmatched_output_rows.append(unmatched_output_row)

    except Exception as e:
        error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
        continue












for T5 in T5_table:
    try:
        matched = False
        matching_invoices = []  # List to store matching invoices for one-to-many match
        rule_index = 0  # Default value for rule index

        for Invoice in Invoice_table:
            if (T5['Auth No'] == Invoice['Auth No'] or T5['Ticket No'] == Invoice['Ticket No']):
                matching_invoices.append(Invoice)

        if matching_invoices:
            invoice_source_amt_sum = sum(invoice['Source Amt'] for invoice in matching_invoices)
            if T5['Source Amt'] == invoice_source_amt_sum:
                matched = True
                description = "One-to-Many Match"
                rule_index = 1  # Set the rule index to the desired value

                for Invoice in matching_invoices:
                    output_row = {
                        column: T5[column] if column in T5 else Invoice[column] for column in output_columns
                    }
                    output_row['Match Rule'] = rule_index
                    output_row['Description'] = description
                    output_rows.append(output_row)

        if not matched:
            unmatched_output_row = {
                column: T5[column] for column in unmatched_output_columns
            }
            unmatched_output_rows.append(unmatched_output_row)

    except Exception as e:
        error_messages.append(f"Error processing T5: {T5}\n{str(e)}")
        continue
